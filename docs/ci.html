<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Bootstrap Examples and the Jackknife | Elements of Nonparametric Statistics</title>
  <meta name="description" content="Course notes for Biostatistics 685/Statistics 560 (Winter 2020)." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Bootstrap Examples and the Jackknife | Elements of Nonparametric Statistics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://nchenderson.github.io/elements-nonpar-stat/" />
  
  <meta property="og:description" content="Course notes for Biostatistics 685/Statistics 560 (Winter 2020)." />
  <meta name="github-repo" content="nchenderson/elements-nonpar-stat" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Bootstrap Examples and the Jackknife | Elements of Nonparametric Statistics" />
  
  <meta name="twitter:description" content="Course notes for Biostatistics 685/Statistics 560 (Winter 2020)." />
  

<meta name="author" content="Nicholas Henderson" />


<meta name="date" content="2020-03-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bootstrap-main.html"/>
<link rel="next" href="kernel-regression-and-local-regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Biostat 685/Stat 560</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#sec:whatisnonpar"><i class="fa fa-check"></i><b>1.1</b> What is Nonparametric Statistics?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#sec:course-outline"><i class="fa fa-check"></i><b>1.2</b> Outline of Course</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#sec:example-nonpar-tests"><i class="fa fa-check"></i><b>1.3</b> Example 1: Nonparametric vs.Â Parametric Two-Sample Testing</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#sec:example-nonpar-estimation"><i class="fa fa-check"></i><b>1.4</b> Example 2: Nonparametric Estimation</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#sec:example-nonpar-confint"><i class="fa fa-check"></i><b>1.5</b> Example 3: Confidence Intervals</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#sec:example-nonpar-regress1"><i class="fa fa-check"></i><b>1.6</b> Example 4: Nonparametric Regression with a Single Covariate</a></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#sec:example-nonpar-regress2"><i class="fa fa-check"></i><b>1.7</b> Example 5: Classification and Regression Trees (CART)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>2</b> Working with R</a></li>
<li class="part"><span><b>I Nonparametric Testing</b></span></li>
<li class="chapter" data-level="3" data-path="rank-tests.html"><a href="rank-tests.html"><i class="fa fa-check"></i><b>3</b> Rank and Sign Statistics</a><ul>
<li class="chapter" data-level="3.1" data-path="rank-tests.html"><a href="rank-tests.html#ranks"><i class="fa fa-check"></i><b>3.1</b> Ranks</a><ul>
<li class="chapter" data-level="3.1.1" data-path="rank-tests.html"><a href="rank-tests.html#definition"><i class="fa fa-check"></i><b>3.1.1</b> Definition</a></li>
<li class="chapter" data-level="3.1.2" data-path="rank-tests.html"><a href="rank-tests.html#handling-ties"><i class="fa fa-check"></i><b>3.1.2</b> Handling Ties</a></li>
<li class="chapter" data-level="3.1.3" data-path="rank-tests.html"><a href="rank-tests.html#properties-of-ranks"><i class="fa fa-check"></i><b>3.1.3</b> Properties of Ranks</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="rank-tests.html"><a href="rank-tests.html#the-wilcoxon-rank-sum-wrs-test-a-two-sample-test"><i class="fa fa-check"></i><b>3.2</b> The Wilcoxon Rank Sum (WRS) Test: A Two-Sample Test</a><ul>
<li class="chapter" data-level="3.2.1" data-path="rank-tests.html"><a href="rank-tests.html#goal-of-the-test"><i class="fa fa-check"></i><b>3.2.1</b> Goal of the Test</a></li>
<li class="chapter" data-level="3.2.2" data-path="rank-tests.html"><a href="rank-tests.html#definition-of-the-wrs-test-statistic"><i class="fa fa-check"></i><b>3.2.2</b> Definition of the WRS Test Statistic</a></li>
<li class="chapter" data-level="3.2.3" data-path="rank-tests.html"><a href="rank-tests.html#computing-p-values-for-the-wrs-test"><i class="fa fa-check"></i><b>3.2.3</b> Computing p-values for the WRS Test</a></li>
<li class="chapter" data-level="3.2.4" data-path="rank-tests.html"><a href="rank-tests.html#computing-the-wrs-test-in-r"><i class="fa fa-check"></i><b>3.2.4</b> Computing the WRS test in R</a></li>
<li class="chapter" data-level="3.2.5" data-path="rank-tests.html"><a href="rank-tests.html#additional-notes-for-the-wrs-test"><i class="fa fa-check"></i><b>3.2.5</b> Additional Notes for the WRS test</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="rank-tests.html"><a href="rank-tests.html#one-sample-tests"><i class="fa fa-check"></i><b>3.3</b> One Sample Tests</a><ul>
<li class="chapter" data-level="3.3.1" data-path="rank-tests.html"><a href="rank-tests.html#sign-test"><i class="fa fa-check"></i><b>3.3.1</b> The Sign Test</a></li>
<li class="chapter" data-level="3.3.2" data-path="rank-tests.html"><a href="rank-tests.html#the-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>3.3.2</b> The Wilcoxon Signed Rank Test</a></li>
<li class="chapter" data-level="3.3.3" data-path="rank-tests.html"><a href="rank-tests.html#using-r-to-perform-the-sign-and-wilcoxon-tests"><i class="fa fa-check"></i><b>3.3.3</b> Using R to Perform the Sign and Wilcoxon Tests</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="rank-tests.html"><a href="rank-tests.html#power-and-comparisons-with-parametric-tests"><i class="fa fa-check"></i><b>3.4</b> Power and Comparisons with Parametric Tests</a><ul>
<li class="chapter" data-level="3.4.1" data-path="rank-tests.html"><a href="rank-tests.html#the-power-function-of-a-test"><i class="fa fa-check"></i><b>3.4.1</b> The Power Function of a Test</a></li>
<li class="chapter" data-level="3.4.2" data-path="rank-tests.html"><a href="rank-tests.html#power-comparisons-and-asymptotic-relative-efficiency"><i class="fa fa-check"></i><b>3.4.2</b> Power Comparisons and Asymptotic Relative Efficiency</a></li>
<li class="chapter" data-level="3.4.3" data-path="rank-tests.html"><a href="rank-tests.html#efficiency-examples"><i class="fa fa-check"></i><b>3.4.3</b> Efficiency Examples</a></li>
<li class="chapter" data-level="3.4.4" data-path="rank-tests.html"><a href="rank-tests.html#efficiency-comparisons-for-several-distributions"><i class="fa fa-check"></i><b>3.4.4</b> Efficiency Comparisons for Several Distributions</a></li>
<li class="chapter" data-level="3.4.5" data-path="rank-tests.html"><a href="rank-tests.html#a-power-contest"><i class="fa fa-check"></i><b>3.4.5</b> A Power âContestâ</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="rank-tests.html"><a href="rank-tests.html#linear-rank-statistics-in-general"><i class="fa fa-check"></i><b>3.5</b> Linear Rank Statistics in General</a><ul>
<li class="chapter" data-level="3.5.1" data-path="rank-tests.html"><a href="rank-tests.html#definition-1"><i class="fa fa-check"></i><b>3.5.1</b> Definition</a></li>
<li class="chapter" data-level="3.5.2" data-path="rank-tests.html"><a href="rank-tests.html#properties-of-linear-rank-statistics"><i class="fa fa-check"></i><b>3.5.2</b> Properties of Linear Rank Statistics</a></li>
<li class="chapter" data-level="3.5.3" data-path="rank-tests.html"><a href="rank-tests.html#other-examples-of-linear-rank-statistics"><i class="fa fa-check"></i><b>3.5.3</b> Other Examples of Linear Rank Statistics</a></li>
<li class="chapter" data-level="3.5.4" data-path="rank-tests.html"><a href="rank-tests.html#choosing-the-scores-a_ni"><i class="fa fa-check"></i><b>3.5.4</b> Choosing the scores <span class="math inline">\(a_{N}(i)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="rank-tests.html"><a href="rank-tests.html#additional-reading"><i class="fa fa-check"></i><b>3.6</b> Additional Reading</a></li>
<li class="chapter" data-level="3.7" data-path="rank-tests.html"><a href="rank-tests.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="krusk-wallis.html"><a href="krusk-wallis.html"><i class="fa fa-check"></i><b>4</b> Rank Tests for Multiple Groups</a><ul>
<li class="chapter" data-level="4.1" data-path="krusk-wallis.html"><a href="krusk-wallis.html#the-kruskal-wallis-test"><i class="fa fa-check"></i><b>4.1</b> The Kruskal-Wallis Test</a><ul>
<li class="chapter" data-level="4.1.1" data-path="krusk-wallis.html"><a href="krusk-wallis.html#definition-2"><i class="fa fa-check"></i><b>4.1.1</b> Definition</a></li>
<li class="chapter" data-level="4.1.2" data-path="krusk-wallis.html"><a href="krusk-wallis.html#asymptotic-distribution-and-connection-to-one-way-anova"><i class="fa fa-check"></i><b>4.1.2</b> Asymptotic Distribution and Connection to One-Way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="krusk-wallis.html"><a href="krusk-wallis.html#performing-the-kruskal-wallis-test-in-r"><i class="fa fa-check"></i><b>4.2</b> Performing the Kruskal-Wallis Test in R</a></li>
<li class="chapter" data-level="4.3" data-path="krusk-wallis.html"><a href="krusk-wallis.html#comparison-of-specific-groups"><i class="fa fa-check"></i><b>4.3</b> Comparison of Specific Groups</a></li>
<li class="chapter" data-level="4.4" data-path="krusk-wallis.html"><a href="krusk-wallis.html#an-additional-example"><i class="fa fa-check"></i><b>4.4</b> An Additional Example</a></li>
<li class="chapter" data-level="4.5" data-path="krusk-wallis.html"><a href="krusk-wallis.html#additional-reading-1"><i class="fa fa-check"></i><b>4.5</b> Additional Reading</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="permutation.html"><a href="permutation.html"><i class="fa fa-check"></i><b>5</b> Permutation Tests</a><ul>
<li class="chapter" data-level="5.1" data-path="permutation.html"><a href="permutation.html#notation"><i class="fa fa-check"></i><b>5.1</b> Notation</a></li>
<li class="chapter" data-level="5.2" data-path="permutation.html"><a href="permutation.html#permutation-tests-for-the-two-sample-problem"><i class="fa fa-check"></i><b>5.2</b> Permutation Tests for the Two-Sample Problem</a><ul>
<li class="chapter" data-level="5.2.1" data-path="permutation.html"><a href="permutation.html#example-1"><i class="fa fa-check"></i><b>5.2.1</b> Example 1</a></li>
<li class="chapter" data-level="5.2.2" data-path="permutation.html"><a href="permutation.html#permutation-test-p-values"><i class="fa fa-check"></i><b>5.2.2</b> Permutation Test p-values</a></li>
<li class="chapter" data-level="5.2.3" data-path="permutation.html"><a href="permutation.html#example-2-ratios-of-means"><i class="fa fa-check"></i><b>5.2.3</b> Example 2: Ratios of Means</a></li>
<li class="chapter" data-level="5.2.4" data-path="permutation.html"><a href="permutation.html#example-3-differences-in-quantiles"><i class="fa fa-check"></i><b>5.2.4</b> Example 3: Differences in Quantiles</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="permutation.html"><a href="permutation.html#the-permutation-test-as-a-conditional-test"><i class="fa fa-check"></i><b>5.3</b> The Permutation Test as a Conditional Test</a></li>
<li class="chapter" data-level="5.4" data-path="permutation.html"><a href="permutation.html#a-permutation-test-for-correlation"><i class="fa fa-check"></i><b>5.4</b> A Permutation Test for Correlation</a></li>
<li class="chapter" data-level="5.5" data-path="permutation.html"><a href="permutation.html#a-permutation-test-for-variable-importance-in-regression-and-machine-learning"><i class="fa fa-check"></i><b>5.5</b> A Permutation Test for Variable Importance in Regression and Machine Learning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ustat.html"><a href="ustat.html"><i class="fa fa-check"></i><b>6</b> U-Statistics</a><ul>
<li class="chapter" data-level="6.1" data-path="ustat.html"><a href="ustat.html#definition-3"><i class="fa fa-check"></i><b>6.1</b> Definition</a></li>
<li class="chapter" data-level="6.2" data-path="ustat.html"><a href="ustat.html#examples"><i class="fa fa-check"></i><b>6.2</b> Examples</a><ul>
<li class="chapter" data-level="6.2.1" data-path="ustat.html"><a href="ustat.html#example-1-the-sample-mean"><i class="fa fa-check"></i><b>6.2.1</b> Example 1: The Sample Mean</a></li>
<li class="chapter" data-level="6.2.2" data-path="ustat.html"><a href="ustat.html#example-2-the-sample-variance"><i class="fa fa-check"></i><b>6.2.2</b> Example 2: The Sample Variance</a></li>
<li class="chapter" data-level="6.2.3" data-path="ustat.html"><a href="ustat.html#example-3-ginis-mean-difference"><i class="fa fa-check"></i><b>6.2.3</b> Example 3: Giniâs Mean Difference</a></li>
<li class="chapter" data-level="6.2.4" data-path="ustat.html"><a href="ustat.html#example-4-wilcoxon-signed-rank-statistic"><i class="fa fa-check"></i><b>6.2.4</b> Example 4: Wilcoxon Signed Rank Statistic</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ustat.html"><a href="ustat.html#inference-using-u-statistics"><i class="fa fa-check"></i><b>6.3</b> Inference using U-statistics</a></li>
<li class="chapter" data-level="6.4" data-path="ustat.html"><a href="ustat.html#u-statistics-for-two-sample-problems"><i class="fa fa-check"></i><b>6.4</b> U-statistics for Two-Sample Problems</a><ul>
<li class="chapter" data-level="6.4.1" data-path="ustat.html"><a href="ustat.html#the-mann-whitney-statistic"><i class="fa fa-check"></i><b>6.4.1</b> The Mann-Whitney Statistic</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ustat.html"><a href="ustat.html#measures-of-association"><i class="fa fa-check"></i><b>6.5</b> Measures of Association</a><ul>
<li class="chapter" data-level="6.5.1" data-path="ustat.html"><a href="ustat.html#spearmans-rank-correlation"><i class="fa fa-check"></i><b>6.5.1</b> Spearmanâs Rank Correlation</a></li>
<li class="chapter" data-level="6.5.2" data-path="ustat.html"><a href="ustat.html#kendalls-tau"><i class="fa fa-check"></i><b>6.5.2</b> Kendallâs tau</a></li>
<li class="chapter" data-level="6.5.3" data-path="ustat.html"><a href="ustat.html#distance-covariance-and-correlation"><i class="fa fa-check"></i><b>6.5.3</b> Distance Covariance and Correlation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Nonparametric Estimation</b></span></li>
<li class="chapter" data-level="7" data-path="edf.html"><a href="edf.html"><i class="fa fa-check"></i><b>7</b> The Empirical Distribution Function</a><ul>
<li class="chapter" data-level="7.1" data-path="edf.html"><a href="edf.html#definition-and-basic-properties"><i class="fa fa-check"></i><b>7.1</b> Definition and Basic Properties</a></li>
<li class="chapter" data-level="7.2" data-path="edf.html"><a href="edf.html#confidence-intervals-for-ft"><i class="fa fa-check"></i><b>7.2</b> Confidence intervals for F(t)</a></li>
<li class="chapter" data-level="7.3" data-path="edf.html"><a href="edf.html#the-empirical-distribution-function-in-r"><i class="fa fa-check"></i><b>7.3</b> The Empirical Distribution Function in R</a></li>
<li class="chapter" data-level="7.4" data-path="edf.html"><a href="edf.html#the-kolmogorov-smirnov-test"><i class="fa fa-check"></i><b>7.4</b> The Kolmogorov-Smirnov Test</a></li>
<li class="chapter" data-level="7.5" data-path="edf.html"><a href="edf.html#the-empirical-distribution-function-and-statistical-functionals"><i class="fa fa-check"></i><b>7.5</b> The empirical distribution function and statistical functionals</a></li>
<li class="chapter" data-level="7.6" data-path="edf.html"><a href="edf.html#additional-reading-2"><i class="fa fa-check"></i><b>7.6</b> Additional Reading</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="density-estimation.html"><a href="density-estimation.html"><i class="fa fa-check"></i><b>8</b> Density Estimation</a><ul>
<li class="chapter" data-level="8.1" data-path="density-estimation.html"><a href="density-estimation.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="density-estimation.html"><a href="density-estimation.html#histograms"><i class="fa fa-check"></i><b>8.2</b> Histograms</a><ul>
<li class="chapter" data-level="8.2.1" data-path="density-estimation.html"><a href="density-estimation.html#definition-5"><i class="fa fa-check"></i><b>8.2.1</b> Definition</a></li>
<li class="chapter" data-level="8.2.2" data-path="density-estimation.html"><a href="density-estimation.html#histograms-in-r"><i class="fa fa-check"></i><b>8.2.2</b> Histograms in R</a></li>
<li class="chapter" data-level="8.2.3" data-path="density-estimation.html"><a href="density-estimation.html#performance-of-the-histogram-estimate-and-bin-width-selection"><i class="fa fa-check"></i><b>8.2.3</b> Performance of the Histogram Estimate and Bin Width Selection</a></li>
<li class="chapter" data-level="8.2.4" data-path="density-estimation.html"><a href="density-estimation.html#choosing-the-histogram-bin-width"><i class="fa fa-check"></i><b>8.2.4</b> Choosing the Histogram Bin Width</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="density-estimation.html"><a href="density-estimation.html#a-box-type-density-estimate"><i class="fa fa-check"></i><b>8.3</b> A Box-type Density Estimate</a></li>
<li class="chapter" data-level="8.4" data-path="density-estimation.html"><a href="density-estimation.html#kernel-density-estimation"><i class="fa fa-check"></i><b>8.4</b> Kernel Density Estimation</a><ul>
<li class="chapter" data-level="8.4.1" data-path="density-estimation.html"><a href="density-estimation.html#definition-6"><i class="fa fa-check"></i><b>8.4.1</b> Definition</a></li>
<li class="chapter" data-level="8.4.2" data-path="density-estimation.html"><a href="density-estimation.html#bias-variance-and-amise-of-kernel-density-estimates"><i class="fa fa-check"></i><b>8.4.2</b> Bias, Variance, and AMISE of Kernel Density Estimates</a></li>
<li class="chapter" data-level="8.4.3" data-path="density-estimation.html"><a href="density-estimation.html#bandwidth-selection-with-the-normal-reference-rule-and-silvermans-rule-of-thumb"><i class="fa fa-check"></i><b>8.4.3</b> Bandwidth Selection with the Normal Reference Rule and Silvermanâs âRule of Thumbâ</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="density-estimation.html"><a href="density-estimation.html#cross-validation-for-bandwidth-selection"><i class="fa fa-check"></i><b>8.5</b> Cross-Validation for Bandwidth Selection</a><ul>
<li class="chapter" data-level="8.5.1" data-path="density-estimation.html"><a href="density-estimation.html#squared-error-cross-validation"><i class="fa fa-check"></i><b>8.5.1</b> Squared-Error Cross-Validation</a></li>
<li class="chapter" data-level="8.5.2" data-path="density-estimation.html"><a href="density-estimation.html#computing-the-cross-validation-bandwidth"><i class="fa fa-check"></i><b>8.5.2</b> Computing the Cross-validation Bandwidth</a></li>
<li class="chapter" data-level="8.5.3" data-path="density-estimation.html"><a href="density-estimation.html#likelihood-cross-validation"><i class="fa fa-check"></i><b>8.5.3</b> Likelihood Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="density-estimation.html"><a href="density-estimation.html#density-estimation-in-r"><i class="fa fa-check"></i><b>8.6</b> Density Estimation in R</a></li>
<li class="chapter" data-level="8.7" data-path="density-estimation.html"><a href="density-estimation.html#additional-reading-3"><i class="fa fa-check"></i><b>8.7</b> Additional Reading</a></li>
</ul></li>
<li class="part"><span><b>III Quantifying Uncertainty</b></span></li>
<li class="chapter" data-level="9" data-path="bootstrap-main.html"><a href="bootstrap-main.html"><i class="fa fa-check"></i><b>9</b> The Bootstrap</a><ul>
<li class="chapter" data-level="9.1" data-path="bootstrap-main.html"><a href="bootstrap-main.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="bootstrap-main.html"><a href="bootstrap-main.html#description-of-the-bootstrap"><i class="fa fa-check"></i><b>9.2</b> Description of the Bootstrap</a><ul>
<li class="chapter" data-level="9.2.1" data-path="bootstrap-main.html"><a href="bootstrap-main.html#description"><i class="fa fa-check"></i><b>9.2.1</b> Description</a></li>
<li class="chapter" data-level="9.2.2" data-path="bootstrap-main.html"><a href="bootstrap-main.html#example-confidence-intervals-for-the-rate-parameter-of-an-exponential-distribution"><i class="fa fa-check"></i><b>9.2.2</b> Example: Confidence Intervals for the Rate Parameter of an Exponential Distribution</a></li>
<li class="chapter" data-level="9.2.3" data-path="bootstrap-main.html"><a href="bootstrap-main.html#example-confidence-intervals-for-the-ratio-of-two-quantiles"><i class="fa fa-check"></i><b>9.2.3</b> Example: Confidence Intervals for the Ratio of Two Quantiles</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="bootstrap-main.html"><a href="bootstrap-main.html#why-is-the-bootstrap-procedure-reasonable"><i class="fa fa-check"></i><b>9.3</b> Why is the Bootstrap Procedure Reasonable?</a></li>
<li class="chapter" data-level="9.4" data-path="bootstrap-main.html"><a href="bootstrap-main.html#pivotal-bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> Pivotal Bootstrap Confidence Intervals</a></li>
<li class="chapter" data-level="9.5" data-path="bootstrap-main.html"><a href="bootstrap-main.html#the-parametric-bootstrap"><i class="fa fa-check"></i><b>9.5</b> The Parametric Bootstrap</a><ul>
<li class="chapter" data-level="9.5.1" data-path="bootstrap-main.html"><a href="bootstrap-main.html#parametric-bootstrap-for-the-median-age-from-the-kidney-data"><i class="fa fa-check"></i><b>9.5.1</b> Parametric Bootstrap for the Median Age from the Kidney Data</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="bootstrap-main.html"><a href="bootstrap-main.html#additional-reading-4"><i class="fa fa-check"></i><b>9.6</b> Additional Reading</a></li>
<li class="chapter" data-level="9.7" data-path="bootstrap-main.html"><a href="bootstrap-main.html#exercises-1"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ci.html"><a href="ci.html"><i class="fa fa-check"></i><b>10</b> Bootstrap Examples and the Jackknife</a><ul>
<li class="chapter" data-level="10.1" data-path="ci.html"><a href="ci.html#the-parametric-bootstrap-for-an-ar1-model"><i class="fa fa-check"></i><b>10.1</b> The Parametric Bootstrap for an AR(1) model</a></li>
<li class="chapter" data-level="10.2" data-path="ci.html"><a href="ci.html#using-the-bootstrap-in-regression"><i class="fa fa-check"></i><b>10.2</b> Using the Bootstrap in Regression</a></li>
</ul></li>
<li class="part"><span><b>IV Nonparametric Regression: Part I</b></span></li>
<li class="chapter" data-level="11" data-path="kernel-regression-and-local-regression.html"><a href="kernel-regression-and-local-regression.html"><i class="fa fa-check"></i><b>11</b> Kernel Regression and Local Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="kernel-regression-and-local-regression.html"><a href="kernel-regression-and-local-regression.html#introduction-2"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="kernel-regression-and-local-regression.html"><a href="kernel-regression-and-local-regression.html#kernel-regression"><i class="fa fa-check"></i><b>11.2</b> Kernel Regression</a><ul>
<li class="chapter" data-level="11.2.1" data-path="kernel-regression-and-local-regression.html"><a href="kernel-regression-and-local-regression.html#the-regressogram"><i class="fa fa-check"></i><b>11.2.1</b> The Regressogram</a></li>
<li class="chapter" data-level="11.2.2" data-path="kernel-regression-and-local-regression.html"><a href="kernel-regression-and-local-regression.html#the-local-average-estimator"><i class="fa fa-check"></i><b>11.2.2</b> The Local Average Estimator</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="kernel-regression-and-local-regression.html"><a href="kernel-regression-and-local-regression.html#additional-reading-5"><i class="fa fa-check"></i><b>11.3</b> Additional Reading</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="inference-for-regression.html"><a href="inference-for-regression.html"><i class="fa fa-check"></i><b>12</b> Splines and Penalized Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="inference-for-regression.html"><a href="inference-for-regression.html#introduction-3"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="inference-for-regression.html"><a href="inference-for-regression.html#spline-basis-functions"><i class="fa fa-check"></i><b>12.2</b> Spline Basis Functions</a></li>
<li class="chapter" data-level="12.3" data-path="inference-for-regression.html"><a href="inference-for-regression.html#smoothing-splinespenalized-regression"><i class="fa fa-check"></i><b>12.3</b> Smoothing Splines/Penalized Regression</a><ul>
<li class="chapter" data-level="12.3.1" data-path="inference-for-regression.html"><a href="inference-for-regression.html#selection-of-smoothing-parameter"><i class="fa fa-check"></i><b>12.3.1</b> Selection of Smoothing Parameter</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Nonparametric Regression: Part II</b></span></li>
<li class="chapter" data-level="13" data-path="decision-tree.html"><a href="decision-tree.html"><i class="fa fa-check"></i><b>13</b> Decision Trees and CART</a></li>
<li class="chapter" data-level="14" data-path="ensemble.html"><a href="ensemble.html"><i class="fa fa-check"></i><b>14</b> Ensemble Methods for Prediction</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elements of Nonparametric Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ci" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Bootstrap Examples and the Jackknife</h1>
<div id="the-parametric-bootstrap-for-an-ar1-model" class="section level2">
<h2><span class="header-section-number">10.1</span> The Parametric Bootstrap for an AR(1) model</h2>
<ul>
<li><p>Consider the time series <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{m}\)</span>. Here,
<span class="math inline">\(X_{t}\)</span> denotes an observation made at time <span class="math inline">\(t\)</span>.</p></li>
<li><p>An autoregressive model of order 1 (usually called an AR(1) model) for this time series is
<span class="math display">\[\begin{eqnarray}
X_{1} &amp;=&amp; \frac{c_{0}}{1 - \alpha} + \varepsilon_{1} \nonumber \\
X_{t} &amp;=&amp; c_{0} + \alpha X_{t-1} + \varepsilon_{t}, \qquad t=2,\ldots,m. \nonumber
\end{eqnarray}\]</span></p></li>
<li><p>It is usually assumed that <span class="math inline">\(|\alpha| &lt; 1\)</span>.</p></li>
<li>In the AR(1) model, it is assumed that
<ul>
<li><span class="math inline">\(E(\varepsilon_{t}) = 0\)</span></li>
<li><span class="math inline">\(\textrm{Var}(\varepsilon_{t}) = \sigma^{2}\)</span>,</li>
<li><span class="math inline">\(\varepsilon_{2}, \ldots, \varepsilon_{m}\)</span> are i.i.d.</li>
<li><span class="math inline">\(\varepsilon_{t}\)</span> and <span class="math inline">\(X_{t-1}\)</span> are independent.</li>
</ul></li>
<li><p>In addition to these assumptions, we will assume that
<span class="math display">\[\begin{equation}
\varepsilon_{t} \sim \textrm{Normal}(0, \sigma^{2})  \nonumber 
\end{equation}\]</span></p></li>
<li><p>The AR(1) model implies that
<span class="math display">\[\begin{equation}
\textrm{Corr}(X_{t}, X_{t-1}) = \alpha  \nonumber 
\end{equation}\]</span>
and, more generally, that
<span class="math display">\[\begin{equation}
\textrm{Corr}(X_{t}, X_{t-p}) = \alpha^{p}  \nonumber
\end{equation}\]</span></p></li>
</ul>
<hr />
<ul>
<li>For known values of <span class="math inline">\(c_{0}, \alpha\)</span>, and <span class="math inline">\(\sigma^{2}\)</span>, we can simulate
an AR(1) time series with the following <code>R</code> code:</li>
</ul>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb186-1" data-line-number="1">SimulateParAR1 &lt;-<span class="st"> </span><span class="cf">function</span>(m, c0, alpha, sig.sq) {</a>
<a class="sourceLine" id="cb186-2" data-line-number="2">     xx &lt;-<span class="st"> </span><span class="kw">numeric</span>(m)</a>
<a class="sourceLine" id="cb186-3" data-line-number="3">     xx[<span class="dv">1</span>] &lt;-<span class="st"> </span>c0<span class="op">/</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha) <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dt">sd=</span><span class="kw">sqrt</span>(sig.sq))</a>
<a class="sourceLine" id="cb186-4" data-line-number="4">     <span class="cf">for</span>(t <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>m) { </a>
<a class="sourceLine" id="cb186-5" data-line-number="5">         xx[t] &lt;-<span class="st"> </span>c0 <span class="op">+</span><span class="st"> </span>alpha<span class="op">*</span>xx[t<span class="dv">-1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dt">sd=</span><span class="kw">sqrt</span>(sig.sq))</a>
<a class="sourceLine" id="cb186-6" data-line-number="6">     }</a>
<a class="sourceLine" id="cb186-7" data-line-number="7">     <span class="kw">return</span>(xx)</a>
<a class="sourceLine" id="cb186-8" data-line-number="8">}</a></code></pre></div>
<p><img src="10-confidence-intervals_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<ul>
<li>In <code>R</code>, estimates of <span class="math inline">\(c_{0}, \alpha,\)</span> and <span class="math inline">\(\sigma^{2}\)</span> can be found by using the <code>ar</code> function. For example,</li>
</ul>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" data-line-number="1">x &lt;-<span class="st"> </span><span class="kw">SimulateParAR1</span>(<span class="dv">1000</span>, <span class="dv">1</span>, <span class="fl">0.8</span>, <span class="dt">sig.sq=</span>.<span class="dv">25</span>)</a>
<a class="sourceLine" id="cb187-2" data-line-number="2">ar1.fit &lt;-<span class="st"> </span><span class="kw">ar</span>(x, <span class="dt">aic=</span><span class="ot">FALSE</span>, <span class="dt">order.max =</span> <span class="dv">1</span>, <span class="dt">method=</span><span class="st">&quot;mle&quot;</span>)</a>
<a class="sourceLine" id="cb187-3" data-line-number="3"></a>
<a class="sourceLine" id="cb187-4" data-line-number="4">c0.est &lt;-<span class="st"> </span>ar1.fit<span class="op">$</span>x.mean<span class="op">*</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>ar1.fit<span class="op">$</span>ar)</a>
<a class="sourceLine" id="cb187-5" data-line-number="5">alpha.est &lt;-<span class="st"> </span>ar1.fit<span class="op">$</span>ar</a>
<a class="sourceLine" id="cb187-6" data-line-number="6">sigsq.est &lt;-<span class="st"> </span>ar1.fit<span class="op">$</span>var.pred</a></code></pre></div>
<hr />
<ul>
<li><p>Suppose we want to construct confidence intervals for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\sigma\)</span> using a bootstrap method.</p></li>
<li><p>Using the direct, nonparametric bootstrap described in the previous chapter will not work
because our observations are not independent. There are âblock bootstrapsâ that
are designed to work for time series, but we will not discuss those here (see e.g., <span class="citation">BÃ¼hlmann (<a href="#ref-buhlmann2002">2002</a>)</span> or Chapter 8 of <span class="citation">Davison and Hinkley (<a href="#ref-davison1997">1997</a>)</span> for
more details).</p></li>
<li><p>With the parametric bootstrap, we only have to use the following steps to generate bootstrap replications
<span class="math inline">\(\hat{\alpha}_{r}^{*}\)</span> and <span class="math inline">\(\hat{\sigma}_{r}^{2,*}\)</span> for estimates of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\hat{\sigma}^{2}\)</span>.</p></li>
<li>For <span class="math inline">\(r = 1, \ldots, R\)</span>:
<ul>
<li>Simulate a time series <span class="math inline">\(X_{1}^{*}, \ldots, X_{m}^{*}\)</span> from an AR(1) model with parameters <span class="math inline">\((\hat{c}_{0}, \hat{\alpha}, \hat{\sigma}^{2})\)</span>.</li>
<li>Compute <span class="math inline">\(\hat{\alpha}_{r}^{*} = \hat{\alpha}(X_{1}^{*}, \ldots, X_{m}^{*})\)</span>.</li>
<li>Compute <span class="math inline">\(\hat{\sigma}_{r}^{2,*} = \hat{\sigma}^{2}(X_{1}^{*}, \ldots, X_{m}^{*})\)</span></li>
</ul></li>
</ul>
<hr />
<ul>
<li>To see how this parametric bootstrap works, we will use the <code>nhtemp</code> dataset that is available in <code>R</code>.</li>
</ul>
<p><img src="10-confidence-intervals_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<ul>
<li>The <code>nhtemp</code> dataset contains the mean annual temperature in New Haven, Connecticut from the years 1912-1971</li>
</ul>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb188-1" data-line-number="1"><span class="kw">head</span>(nhtemp)</a></code></pre></div>
<pre><code>## [1] 49.9 52.3 49.4 51.1 49.4 47.9</code></pre>
<ul>
<li>The estimated autocorrelation parameter <span class="math inline">\(\alpha\)</span> is about <span class="math inline">\(0.31\)</span> for this data</li>
</ul>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" data-line-number="1">ar1.temp &lt;-<span class="st"> </span><span class="kw">ar</span>(nhtemp, <span class="dt">aic=</span><span class="ot">FALSE</span>, <span class="dt">order.max =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb190-2" data-line-number="2">c0.hat &lt;-<span class="st"> </span>ar1.temp<span class="op">$</span>x.mean<span class="op">*</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>ar1.temp<span class="op">$</span>ar)</a>
<a class="sourceLine" id="cb190-3" data-line-number="3">alpha.hat &lt;-<span class="st"> </span>ar1.temp<span class="op">$</span>ar</a>
<a class="sourceLine" id="cb190-4" data-line-number="4">sigsq.hat &lt;-<span class="st"> </span>ar1.temp<span class="op">$</span>var.pred</a>
<a class="sourceLine" id="cb190-5" data-line-number="5">alpha.hat</a></code></pre></div>
<pre><code>## [1] 0.3148269</code></pre>
<ul>
<li>Now, that we have estimated all the parameter of the AR(1) model, we can run our parametric bootstrap for <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\sigma}\)</span>:</li>
</ul>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" data-line-number="1">R &lt;-<span class="st"> </span><span class="dv">500</span></a>
<a class="sourceLine" id="cb192-2" data-line-number="2">alpha.boot &lt;-<span class="st"> </span><span class="kw">numeric</span>(R)</a>
<a class="sourceLine" id="cb192-3" data-line-number="3">sigsq.boot &lt;-<span class="st"> </span><span class="kw">numeric</span>(R)</a>
<a class="sourceLine" id="cb192-4" data-line-number="4"><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>R) {</a>
<a class="sourceLine" id="cb192-5" data-line-number="5">  x &lt;-<span class="st"> </span><span class="kw">SimulateParAR1</span>(<span class="dv">60</span>, <span class="dt">c0=</span>c0.hat, <span class="dt">alpha=</span>alpha.hat, <span class="dt">sig.sq=</span>sigsq.hat)</a>
<a class="sourceLine" id="cb192-6" data-line-number="6">  ar1.fit &lt;-<span class="st"> </span><span class="kw">ar</span>(x, <span class="dt">aic=</span><span class="ot">FALSE</span>, <span class="dt">order.max =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb192-7" data-line-number="7">  </a>
<a class="sourceLine" id="cb192-8" data-line-number="8">  alpha.boot[r] &lt;-<span class="st"> </span>ar1.fit<span class="op">$</span>ar</a>
<a class="sourceLine" id="cb192-9" data-line-number="9">  sigsq.boot[r] &lt;-<span class="st"> </span>ar1.fit<span class="op">$</span>var.pred</a>
<a class="sourceLine" id="cb192-10" data-line-number="10">}</a></code></pre></div>
<ul>
<li>Normal bootstrap standard error confidence intervals for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\sigma^{2}\)</span> are</li>
</ul>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb193-1" data-line-number="1"><span class="kw">round</span>(<span class="kw">c</span>(alpha.hat <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span><span class="kw">sd</span>(alpha.boot), alpha.hat <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span><span class="kw">sd</span>(alpha.boot)), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.069 0.561</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb195-1" data-line-number="1"><span class="kw">round</span>(<span class="kw">c</span>(sigsq.hat <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span><span class="kw">sd</span>(sigsq.boot), sigsq.hat <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span><span class="kw">sd</span>(sigsq.boot)), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.940 1.996</code></pre>
<ul>
<li>We can compare our confidence interval for <span class="math inline">\(\alpha\)</span> with the confidence interval
obtained from using a large-sample approximation:</li>
</ul>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" data-line-number="1">asymp.se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(ar1.temp<span class="op">$</span>asy.var.coef)</a>
<a class="sourceLine" id="cb197-2" data-line-number="2"><span class="kw">round</span>(<span class="kw">c</span>(alpha.hat <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>asymp.se, alpha.hat <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>asymp.se), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.071 0.559</code></pre>
</div>
<div id="using-the-bootstrap-in-regression" class="section level2">
<h2><span class="header-section-number">10.2</span> Using the Bootstrap in Regression</h2>
<ul>
<li>In linear regression with a single, univariate covariate, we work with the following model
<span class="math display">\[\begin{equation}
Y_{i} = \beta_{0} + \beta_{1}x_{i} + \varepsilon_{i}, \qquad i = 1, \ldots, n.  \nonumber 
\end{equation}\]</span>
<ul>
<li><span class="math inline">\(Y_{i}\)</span> - the responses</li>
<li><span class="math inline">\(x_{i}\)</span> - the covariates</li>
<li><span class="math inline">\(\beta_{0}, \beta_{1}\)</span> - the regression coefficients</li>
<li><span class="math inline">\(\varepsilon_{i}\)</span> - the residuals</li>
</ul></li>
<li><p>Typically, confidence intervals for the regression coefficients <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>
are constructed under the assumption that <span class="math inline">\(\varepsilon_{i} \sim \textrm{Normal}(0, \sigma^{2})\)</span>.</p></li>
<li><p>The bootstrap allows us to compute confidence intervals for <span class="math inline">\((\beta_{0}, \beta_{1})\)</span> without
relying on this normality assumption.</p></li>
<li><p>How to compute bootstrap confidence intervals for <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>?</p></li>
</ul>
<hr />
<ul>
<li><p>The least-squares estimates of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> are
<span class="math display">\[\begin{equation}
\hat{\beta}_{0} = \bar{y} - \hat{\beta}_{1}\bar{x} \qquad \qquad \hat{\beta}_{1} = \frac{\sum_{i=1}^{n}(x_{i} - \bar{x})(y_{i} - \bar{y})}{S_{xx}}  \nonumber
\end{equation}\]</span>
where <span class="math inline">\(S_{xx} = \sum_{i=1}^{n}( x_{i} - \bar{x})^{2}\)</span>.</p></li>
<li><p>Assuming the covariates are fixed design points, the variance of <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> are
<span class="math display">\[\begin{equation}
\textrm{Var}(\hat{\beta}_{0}) = \sigma^{2}\Big(\frac{1}{n} + \frac{\bar{x}}{S_{xx}} \Big) \qquad \textrm{Var}(\hat{\beta}_{1}) = \frac{\sigma^{2}}{S_{xx}} \nonumber
\end{equation}\]</span></p></li>
</ul>
<hr />
<p><strong>Parametric Bootstrap for Regression</strong></p>
<ul>
<li><p>With a parametric bootstrap, we will simulate outcomes <span class="math inline">\(Y_{i}\)</span> from the model
<span class="math display">\[\begin{equation}
Y_{i} = \hat{\beta}_{0} + \hat{\beta}_{1}x_{i} + \varepsilon_{i},  \nonumber
\end{equation}\]</span>
where <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> are the least-squares estimates of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>.</p></li>
<li><p>It is most common to assume that <span class="math inline">\(\varepsilon_{i} \sim \textrm{Normal}(0, \hat{\sigma}^{2})\)</span>,
where <span class="math inline">\(\hat{\sigma}^{2}\)</span> is an estimate of the residual variance.</p></li>
<li><p>However, we could easily use an alternative parametric model for <span class="math inline">\(\varepsilon_{i}\)</span> if we thought
it was appropriate.</p></li>
</ul>
<hr />
<ul>
<li><p>A t-distribution with a small number of degrees of freedom can be useful
when the residuals are thought to follow a distribution with âheavier tailsâ.</p></li>
<li><p>If we assume <span class="math inline">\(\varepsilon_{i} \sim \sigma t_{3}\)</span>, then <span class="math inline">\(\textrm{Var}(\varepsilon_{i}) = 3\sigma^{2}\)</span>.</p></li>
<li><p>So, with a <span class="math inline">\(t_{3}\)</span> residual distribution we want to simulate from the model
<span class="math display">\[\begin{equation}
Y_{i} = \hat{\beta}_{0} + \hat{\beta}_{1}x_{i} + \frac{\hat{\sigma}}{\sqrt{3}}u_{i},  \qquad u_{i} \sim t_{3},
\end{equation}\]</span>
where <span class="math inline">\(\hat{\sigma}^{2}\)</span> is the following estimate of the residual variance:
<span class="math display">\[\begin{equation}
\hat{\sigma}^{2} = \tfrac{1}{n-2}\sum_{i=1}^{n} (Y_{i} - \hat{\beta}_{0} - \hat{\beta}_{1})^{2}
\end{equation}\]</span></p></li>
</ul>
<hr />
<ul>
<li><p>To show how this parametric-t bootstrap works in practice we will look
at the kidney function data.</p></li>
<li><p>We will look at a linear regression where the measure of kidney function is
the outcome and age is the covariate.</p></li>
</ul>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb199-1" data-line-number="1">kidney &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;https://web.stanford.edu/~hastie/CASI_files/DATA/kidney.txt&quot;</span>, </a>
<a class="sourceLine" id="cb199-2" data-line-number="2">                     <span class="dt">header=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="10-confidence-intervals_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<ul>
<li>Bootstrap replications of <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> can
be computed using the following <code>R</code> code:</li>
</ul>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" data-line-number="1"><span class="co">## First find the parameter estimates</span></a>
<a class="sourceLine" id="cb200-2" data-line-number="2">lm.kidney &lt;-<span class="st"> </span><span class="kw">lm</span>(tot <span class="op">~</span><span class="st"> </span>age, <span class="dt">data=</span>kidney)</a>
<a class="sourceLine" id="cb200-3" data-line-number="3">beta0.hat &lt;-<span class="st"> </span>lm.kidney<span class="op">$</span>coef[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb200-4" data-line-number="4">beta1.hat &lt;-<span class="st"> </span>lm.kidney<span class="op">$</span>coef[<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb200-5" data-line-number="5">sigsq.hat &lt;-<span class="st"> </span><span class="kw">sum</span>(lm.kidney<span class="op">$</span>residuals<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">157</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb200-6" data-line-number="6"></a>
<a class="sourceLine" id="cb200-7" data-line-number="7"><span class="co">## Using these estimates, run a parametric bootstrap to generate</span></a>
<a class="sourceLine" id="cb200-8" data-line-number="8"><span class="co">## bootstrap replications of beta0.hat and beta1.hat</span></a>
<a class="sourceLine" id="cb200-9" data-line-number="9">R &lt;-<span class="st"> </span><span class="dv">500</span></a>
<a class="sourceLine" id="cb200-10" data-line-number="10">beta0.boot &lt;-<span class="st"> </span><span class="kw">numeric</span>(R)</a>
<a class="sourceLine" id="cb200-11" data-line-number="11">beta1.boot &lt;-<span class="st"> </span><span class="kw">numeric</span>(R)</a>
<a class="sourceLine" id="cb200-12" data-line-number="12"><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>R) {</a>
<a class="sourceLine" id="cb200-13" data-line-number="13">  ysim &lt;-<span class="st"> </span>beta0.hat <span class="op">+</span><span class="st"> </span>beta1.hat<span class="op">*</span>kidney<span class="op">$</span>age <span class="op">+</span><span class="st"> </span><span class="kw">sqrt</span>(sigsq.hat<span class="op">/</span><span class="dv">3</span>)<span class="op">*</span><span class="kw">rt</span>(<span class="dv">157</span>, <span class="dt">df=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb200-14" data-line-number="14">  lm.boot &lt;-<span class="st"> </span><span class="kw">lm</span>(ysim <span class="op">~</span><span class="st"> </span>kidney<span class="op">$</span>age)</a>
<a class="sourceLine" id="cb200-15" data-line-number="15">  </a>
<a class="sourceLine" id="cb200-16" data-line-number="16">  beta0.boot[r] &lt;-<span class="st"> </span>lm.boot<span class="op">$</span>coef[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb200-17" data-line-number="17">  beta1.boot[r] &lt;-<span class="st"> </span>lm.boot<span class="op">$</span>coef[<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb200-18" data-line-number="18">}</a></code></pre></div>

</div>
</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-buhlmann2002">
<p>BÃ¼hlmann, Peter. 2002. âBootstraps for Time Series.â <em>Statistical Science</em>, 52â72.</p>
</div>
<div id="ref-davison1997">
<p>Davison, Anthony Christopher, and David Victor Hinkley. 1997. <em>Bootstrap Methods and Their Application</em>. Vol. 1. Cambridge university press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bootstrap-main.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="kernel-regression-and-local-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ElementsNonparStat.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
