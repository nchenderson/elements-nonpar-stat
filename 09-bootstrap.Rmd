# (PART) Quantifying Uncertainty {-} 

# The Bootstrap {#bootstrap-main}

## Introduction

* The jackknife and the bootstrap are nonparametric procedures that are mainly used for finding standard errors
and constructing confidence intervals.

**Why use the bootstrap?**

1. To find better standard errors and/or confidence intervals when the standard approximations do not work very well.
1. To find standard errors and/or confidence intervals when you have no idea how to compute reasonable standard errors.


---

**Example: Inference for $e^{\mu}$**

* Suppose we have i.i.d. data $X_{1}, \ldots, X_{n} \sim \textrm{Logistic}( \mu, s)$,
meaning that $E(X_{i}) = \mu$ and $\textrm{Var}(X_{i}) = \sigma^{2} = s^{2}\pi^{2}/3$.

* Suppose our goal is to construct a confidence interval for the parameter $\theta = e^{\mu}$.

* The traditional approach to constructing a confidence interval uses the fact that
\begin{equation}
\sqrt{n}\Big( e^{\bar{X}} - e^{\mu} \Big) \longrightarrow \textrm{Normal}(0, \sigma^{2}e^{2\mu}) \nonumber
\end{equation}
so that we can assume $e^{\bar{X}}$ has a roughly Normal distribution with mean $e^{\mu}$ 
and standard deviation $\sigma e^{\mu}/\sqrt{n}$. This approximation is based on 
a Central Limit Theorem and "delta method" argument.

* The estimated standard error in this case is
\begin{equation}
\frac{\hat{\sigma}e^{\bar{X}}}{\sqrt{n}} \nonumber
\end{equation}

* Using this Normal approximation for $e^{\bar{X}}$, the $95\%$ confidence interval for
$e^{\mu}$ is
\begin{equation}
\Big[ e^{\bar{X}} - 1.96 \times \frac{\hat{\sigma}e^{\bar{X}}}{\sqrt{n}},
e^{\bar{X}} + 1.96 \times \frac{\hat{\sigma}e^{\bar{X}}}{\sqrt{n}}
\Big]
(\#eq:normal-approx-emu)
\end{equation}

---

* For specific choices of $n$, how good is the Normal approximation for the distribution of $e^{\bar{X}}$?

* The figure below shows a histogram for the simulated distribution of $e^{\bar{X}}$ when $n=50$.
The density of the Normal approximation is also shown in this figure.

```{r, echo=FALSE, fig.cap="Histogram of simulated values of exp(sample mean) with density of the Normal approximation overlaid. This assumes n=50 and that the data are from a Logistic distribution with mu = 2 and s = 2.", fig.height=6}

set.seed(5138)
R <- 500   ## number of bootstrap replications
ex <- rep(0, R)
ss <- 2
n <- 50
for(k in 1:R) {
   xx <- rlogis(n, location=2, scale=ss)
   ex[k] <- exp(mean(xx))  ## compute mean of bootstrap sample
}
tt <- seq(-10, 40, length.out=1000)
hist(ex, breaks="FD", las=1, col="grey", prob=TRUE,
     main=expression(paste("Simulated Distribution of ", exp(bar(X)), " and its Normal approximation")),
     xlab=expression(exp(bar(X))), xlim=c(-10, 40))
gg <- (exp(2)*ss*pi)/sqrt(3*n)
lines(tt, dnorm(tt, mean=exp(2), sd=gg), lwd=2)
```

* As we can see from the above histogram, the Normal approximation is not terrible. However, 
it really does not capture the skewness in the distribution of $e^{\bar{X}}$ correctly.

* This could effect the coverage performance of confidence intervals which use
Normal approximation \@ref(eq:normal-approx-emu).

* The bootstrap offers an alternative approach for constructing confidence
intervals which does not depend on parametric approximations such as \@ref(eq:normal-approx-emu).


---

**Example: Inference for the Correlation**

* The sample correlation $\hat{\rho}$ which estimates the correlation $\rho = \textrm{Corr}(X_{i}, Y_{i})$
between $X_{i}$ and $Y_{i}$ is defined as
\begin{equation}
\hat{\rho} = \frac{\sum_{i=1}^{n}(X_{i} - \bar{X})(Y_{i} - \bar{Y})}{\sqrt{\sum_{i=1}^{n}(X_{i} - \bar{X})^{2}}\sqrt{\sum_{i=1}^{n}(Y_{i} - \bar{Y})}} \nonumber
\end{equation}

* Even such a relatively straightforward estimate has a pretty complicated formula for the estimated standard error if 
you use a multivariate delta method argument:
\begin{equation}
\textrm{std.err}_{corr}
= \Bigg\{ \frac{\hat{\rho}^{2}}{4n}\Bigg[ \frac{\hat{\mu}_{40}}{\hat{\mu}_{20}^{2}} + \frac{\hat{\mu}_{04}}{\hat{\mu}_{02}^{2}} + \frac{2\hat{\mu}_{22}}{\hat{\mu}_{20}\hat{\mu}_{02} } + \frac{4\hat{\mu}_{22}}{\hat{\mu}_{11}^{2}} - \frac{4\hat{\mu}_{31}}{\hat{\mu}_{11}\hat{\mu}_{20} } - \frac{4\hat{\mu}_{13}}{\hat{\mu}_{11}\hat{\mu}_{02} } \Bigg] \Bigg\}^{1/2}
(\#eq:rho-stderr)
\end{equation}
where
\begin{equation}
\hat{\mu}_{hk} = \sum_{i=1}^{n}(X_{i} - \bar{X})^{h}(Y_{i} - \bar{Y})^{k} \nonumber
\end{equation}

* Another popular approach for constructing a confidence interval is to use Fisher's "z-transformation"
\begin{equation}
z = \frac{1}{2} \ln\Big( \frac{1 + \hat{\rho}}{1 - \hat{\rho}}  \Big)
(\#eq:rho-stderr-ztrans)
\end{equation}
where it is argued that $z$ has a roughly Normal distribution with mean
$\tfrac{1}{2}\ln\{ (1 + \rho)/(1 - \rho) \}$ and standard deviation $1/\sqrt{n - 3}$.

---

* The bootstrap allows us to totally bypass the need to derive tedious formulas for the standard error such as
\@ref(eq:rho-stderr) or bypass the need to use clever transformations such as \@ref(eq:rho-stderr-ztrans). 

* For many more complicated estimates deriving formulas such as \@ref(eq:rho-stderr) or transformations such 
as \@ref(eq:rho-stderr-ztrans) may not even be feasible.

* The bootstrap provides an automatic way of constructing confidence intervals. You only 
need to be able to compute the estimate of interest.



## Description of the Bootstrap

### Description

* Suppose we have a statistic $T_{n}$ that is an estimate of some quantity of interest $\theta$.

* For example:
    + $T_{n}$ - sample mean, $\theta = E(X_{1})$.
    + $T_{n}$ - sample correlation, $\theta = \textrm{Corr}(X_{1}, Y_{1})$.
    + $T_{n}$ - sample median, $\theta = F^{-1}(1/2)$; that is, the true median. 

* Typically, $T_{n}$ can be represented as a function of our sample $X_{1}, \ldots, X_{n}$
\begin{equation}
T_{n} = h\Big( X_{1}, \ldots, X_{n}   \Big)  \nonumber
\end{equation}

* Suppose we want to estimate the standard deviation of $T_{n}$. 

* The true standard deviation of $T_{n}$ is referred to as the **standard error**. 

* Confidence intervals are often based on subtracting or adding an estimate of the standard error, 
e.g.
\begin{equation}
CI = T_{n} \pm z_{\alpha/2} \times \widehat{\textrm{standard error}},  \nonumber 
\end{equation}
where $z_{\alpha/2}$ is the $100 \times (1 - \alpha/2)$ percentile of the $\textrm{Normal}(0,1)$ distribution.

* The bootstrap estimates the standard deviation of $T_{n}$ by repeatedly subsampling from 
the original data and computing the value of the statistic $T_{n}$ on each subsample. 

* More generally, we can use the bootstrap not just to find the standard deviation of $T_{n}$
but to characterize the distribution of $T_{n}$.

---

**The Bootstrap Procedure**

* In our description of the bootstrap, we will assume that we have the following ingredients:
    + $\mathbf{X} = (X_{1}, \ldots, X_{n})$ where $X_{1}, \ldots, X_{n}$ are i.i.d. observations.
    + The statistic $T_{n}$ of interest. $T_{n} = h(X_{1}, \ldots, X_{n})$.
    + $T_{n}$ is an estimate of $\theta$.
    + $R$ - the number of bootstrap replications.

* The bootstrap works in the following way:
* For $r = 1, \ldots, R$:
    + Draw a sample of size $n$: $(X_{1}^{*}, \ldots, X_{n}^{*})$ by sampling with replacement from $\mathbf{X}$.
    + Compute $T_{n,r}^{*} = h(X_{1}^{*}, \ldots, X_{n}^{*})$. 

---

* Each sample is $(X_{1}^{*}, \ldots, X_{n}^{*})$ is drawn through simple random sampling with replacement. 
That is, $X_{1}^{*}, \ldots, X_{n}^{*}$ are independent with 
\begin{equation}
P(X_{i}^{*} = X_{j}) = \frac{1}{n} \quad \textrm{ for } j=1,\ldots,n \nonumber
\end{equation}

* We will refer to each sample $(X_{1}^{*}, \ldots, X_{n}^{*})$ as a **bootstrap sample**.

* We will refer to $T_{n,r}^{*}$ as a **bootstrap replication**.

* The bootstrap estimate for the standard error of $T_{n}$ is
\begin{equation}
se_{boot} = \Bigg[ \frac{1}{R-1} \sum_{r=1}^{R} \Big( T_{n,r}^{*} - \frac{1}{R} \sum_{r=1}^{R} T_{n,r}^{*} \Big)^{2} \Bigg]^{1/2} \nonumber
\end{equation}

* We can even use our bootstrap replications to get an approximation $\hat{G}_{n}^{*}(t)$ for the cumulative distribution function 
$G_{n}(t) = P(T_{n} \leq t)$ of $T_{n}$:
\begin{equation}
\hat{G}_{n}^{*}(t) = \frac{1}{R} \sum_{r=1}^{R} I\Big( T_{n,r}^{*} \leq t \Big) \nonumber
\end{equation}

---

* The **normal bootstrap standard error confidence interval** is defined as 
\begin{equation}
\Big[ T_{n} - z_{\alpha/2} se_{boot}, T_{n} + z_{\alpha/2}se_{boot} \Big] \nonumber
\end{equation}

* The **bootstrap percentile confidence interval** uses the percentiles of the
boostrap replications $T_{n,1}^{*}, \ldots, T_{n,R}^{*}$ to form a confidence interval.

* The bootstrap $100 \times \alpha/2$ and $100 \times (1 - \alpha/2)$ percentiles are roughly defined as
\begin{eqnarray}
T_{[\alpha/2]}^{boot} &=& \textrm{the point } t^{*} \textrm{ such that } 100\alpha/2 \textrm{ of the bootstrap replications are less than } t^{*} \nonumber \\
T_{1 - [\alpha/2]}^{boot} &=& \textrm{the point } t^{*} \textrm{ such that } 100\alpha/2 \textrm{ of the bootstrap replications are less than } t^{*} \nonumber 
\end{eqnarray}

* The level $100 \times (1 - \alpha) \%$ level boostrap percentile confidence interval 
is then
\begin{equation}
\Big[ T_{[\alpha/2]}^{boot}, T_{[1 - \alpha/2]}^{boot} \Big]  \nonumber
\end{equation}

* More precisely, the bootstrap percentiles are obtained by looking at the inverse of the estimated cdf of $T_{n}$
\begin{equation}
T_{[\alpha/2]}^{boot} = \hat{G}_{n}^{*, -1}(\alpha/2)  \qquad  T_{[1 - \alpha/2]}^{boot} = \hat{G}_{n}^{*, -1}(1 - \alpha/2) \nonumber
\end{equation}

---

* The bootstrap approach for computing estimated standard errors and confidence intervals
is very appealing due to the fact that it is **automatic**.

* That is, we do not need to expend any effort deriving formulas for the variance of $T_{n}$
and/or making asymptotic arguments for the distribution of $T_{n}$.

* We only need to be able to compute $T_{n}$ many times, and the bootstrap procedure
will automatically produce a confidence interval for us.


### Example: Confidence Intervals for the Rate Parameter of an Exponential Distribution

* Suppose we have i.i.d. data $X_{1}, \ldots, X_{n}$ from an Exponential distribution with rate parameter $1/\lambda$.
That is, the pdf of $X_{i}$ is
\begin{equation}
f(x)
= \begin{cases}
\frac{1}{\lambda}e^{-x/\lambda} & \text{  if  }  x > 0 \nonumber \\
0  & \text{ otherwise }
\end{cases}
\end{equation}

* This means that 
\begin{equation}
E( X_{i} )  = \lambda \quad \textrm{ and } \quad \textrm{Var}( X_{i} ) = \lambda^{2} \nonumber
\end{equation}

* If using the usual Normal approximation for constructing a confidence interval for $\lambda$, you would
rely on the following asymptotic result:
\begin{equation}
\frac{\sqrt{n}(\bar{X} - \lambda)}{ \bar{X} }  \longrightarrow \textrm{Normal}(0, 1) \nonumber
\end{equation}

* In other words, for large $n$, $\bar{X}$ has an approximately Normal distribution with mean $\lambda$
and standard deviation $\bar{X}/\sqrt{n}$.


* The estimated standard error in this case is $\bar{X}/\sqrt{n}$, and a $95\%$ confidence interval for $\lambda$ is 
\begin{equation}
\Bigg[ \bar{X} - 1.96 \times \frac{\bar{X}}{\sqrt{n}}, \bar{X} + 1.96 \times \frac{\bar{X}}{\sqrt{n}} \Bigg] \nonumber
\end{equation}

---

* Let's do a small simulation to see how the Normal approximation confidence interval compares with
bootstrap-based confidence intervals.

* We will compare the Normal-approximation confidence interval with both the normal standard error bootstrap
confidence interval and the percentile bootstrap confidence interval. 

```{r, echo=FALSE}
set.seed(5618)
```

```{r}
xx <- rexp(50, rate=2) ## data, sample of 50 exponential r.v.s with mean 1/2
R <- 500   ## number of bootstrap replications
boot.mean <- rep(0, R)
for(r in 1:R) {
   boot.samp <- sample(1:50, size=50, replace=TRUE)
   xx.boot <- xx[boot.samp]   ## this is the bootstrap sample
   boot.mean[r] <- mean(xx.boot)  ## this is the rth bootstrap replication
}
```

```{r}
par.ci <- c(mean(xx) - 1.96*mean(xx)/sqrt(50), mean(xx) + 1.96*mean(xx)/sqrt(50))
boot.ci.sd <- c(mean(xx) - 1.96*sd(boot.mean), mean(xx) + 1.96*sd(boot.mean))
boot.ci.quant <- quantile(boot.mean, probs=c(.025, .975))
```

* The normal-approximation confidence interval is
```{r}
round(par.ci, 2)
```
* The standard error boostrap confidence interval is
```{r}
round(boot.ci.sd, 2)
```
* The percentile bootstrap confidence interval
```{r}
round(boot.ci.quant, 2)
```

```{r, echo=FALSE}
hist(boot.mean, breaks="FD", main="Bootstrap Distribution of Sample Mean", 
     xlab="x", col="grey", las=1)
abline(v=boot.ci.quant[1], lwd=2)
abline(v=boot.ci.quant[2], lwd=2)
```


### Example: Confidence Intervals for the Ratio of Two Quantiles

* Suppose we have data from two groups
\begin{eqnarray}
&& \textrm{Group 1: }  X_{1}, \ldots, X_{n} \sim F_{X}  \nonumber \\
&& \textrm{Group 2: }  Y_{1}, \ldots, Y_{n} \sim F_{Y} \nonumber 
\end{eqnarray}

* The pth quantile for group 1 is defined as $\theta_{p1} = F_{X}^{-1}(p)$.
In other words, if $F_{X}$ is continuous then
\begin{equation}
P(X_{i} \leq \theta_{p1}) = F_{X}(F_{X}^{-1}(p)) = p  \nonumber 
\end{equation}

* Likewise, the pth quantile for group 2 is defined as $\theta_{p2} = F_{Y}^{-1}(p)$

* Suppose we are interested in estimating and constructing a confidence for the following parameter
\begin{equation}
\eta = \frac{ \theta_{p1}}{ \theta_{p2} } \nonumber
\end{equation}

---

* We will let $\hat{\theta}_{p1}$ denote the
pth sample quantile from $(X_{1}, \ldots, X_{n})$ and let
$\hat{\theta}_{p2}$ denote the pth sample quantile from $(Y_{1}, \ldots, Y_{n})$.

* We will estimate $\eta$ with the ratio of the sample quantiles
\begin{equation}
\hat{\eta} = \frac{  \hat{\theta}_{p1}  }{ \hat{\theta}_{p2} }  \nonumber 
\end{equation}

* It can be shown that
\begin{equation}
\hat{\theta}_{p1} \textrm{ has an approximate } \textrm{Normal}\Bigg( \theta_{p1}, \frac{p(1-p)}{n f_{X}^{2}(\theta_{p1})} \Bigg) \textrm{ distribution},  \nonumber 
\end{equation}
where $f_{X}(t) = F_{X}'(t)$ is the probability density function of $X_{i}$.

* Using a multivariate delta method argument, you can show that
\begin{equation}
\hat{\eta} \textrm{ has an approximate } \textrm{Normal}\Bigg( \eta, \frac{p(1-p)}{n f_{X}^{2}(\theta_{p1})\theta_{p2}^{2} } + \frac{p(1-p)\theta_{p1}^{2} }{n f_{Y}^{2}(\theta_{p2})\theta_{p2}^{4} } \Bigg) \textrm{ distribution} 
(\#eq:quantile-ratio-approx)
\end{equation}

* Using the above large-sample approximation, the estimated standard error that can be used to construct 
a confidence interval for $\eta$ is
\begin{equation}
\sqrt{\frac{p(1-p)}{n \hat{f}_{X}^{2}(\hat{\theta}_{p1})\hat{\theta}_{p2}^{2} } + \frac{p(1-p)\hat{\theta}_{p1}^{2} }{n \hat{f}_{Y}^{2}(\hat{\theta}_{p2})\hat{\theta}_{p2}^{4} } }  \nonumber 
\end{equation}

---

* Let's do a small simulation study to see how the confidence interval based on the large-sample approximation \@ref(eq:quantile-ratio-approx) 
compares with bootstrap-based confidence intervals.

```{r, echo=FALSE}
set.seed(5618)
```

* We will simulate $X_{i} \sim \textrm{Gamma}(2, 1.5)$ and $Y_{i} \sim \textrm{Gamma}(2, 2)$ with $n = 100$ and $m = 100$. 
```{r}
n <- 100
m <- 100
xx <- rgamma(n, shape=2, rate=1.5) 
yy <- rgamma(m, shape=2, rate=2)
```

* We will focus on estimating the pth quantile ratio for $p = 0.9$. In this case, the
true value of $\eta$ is $\eta \approx 4/3$.

* The estimate $\hat{\eta}$ and the estimated standard error using the large-sample approximation \@ref(eq:quantile-ratio-approx) is
```{r}
theta.hat1 <- quantile(xx, probs=0.9)
theta.hat2 <- quantile(yy, probs=0.9)
eta.hat <- theta.hat1/theta.hat2    ## estimate of quantile ratio

xdensity <- density(xx)
ydensity <- density(yy)
fx <- approxfun(xdensity$x, xdensity$y)(theta.hat1)
fy <- approxfun(ydensity$x, ydensity$y)(theta.hat2)

q1.se.sq <- (.9*.1)/(n*(fx*theta.hat2)^2)
q2.se.sq <- (.9*.1*theta.hat1*theta.hat1)/(n*fy*fy*((theta.hat2)^4))
std.err <- sqrt(q1.se.sq + q2.se.sq)
```

* The confidence interval using the large-sample approximation \@ref(eq:quantile-ratio-approx) is
```{r}
CI <- c(eta.hat - 1.96*std.err, eta.hat + 1.96*std.err)
round(CI, 2)
```

---

* Now, using the same simulated data, let's compute $500$ bootstrap replications of the statistic $\hat{\eta}$
```{r}
R <- 500
eta.boot <- numeric(R)

for(r in 1:R)
{
  boot.xx <- sample(xx, size=n, replace = TRUE)
  boot.yy <- sample(yy, size=m, replace = TRUE)
  thetahat.p1 <- quantile(boot.xx, probs=0.9)
  thetahat.p2 <- quantile(boot.yy, probs=0.9)
  eta.boot[r] <- thetahat.p1/thetahat.p2
}
```

```{r, echo=FALSE}
names(eta.boot) <- NULL
names(eta.hat) <- NULL
```

* Because this is a two-sample setting, we draw bootstrap samples $(X_{1}^{*}, \ldots, X_{n}^{*})$ and $(Y_{1}^{*}, \ldots, Y_{m}^{*})$ for each group separately to generate each bootstrap replications.


* The standard error boostrap confidence interval is
```{r}
boot.ci.sd <- c(eta.hat - 1.96*sd(eta.boot), eta.hat + 1.96*sd(eta.boot))

round(boot.ci.sd, 2)
```

* The percentile bootstrap confidence interval is
```{r}
boot.ci.quant <- quantile(eta.boot, probs=c(.025, .975))
round(boot.ci.quant, 2)
```

* A histogram of the bootstrap replications of $\hat{\eta}$ is shown in the below figure. Note that the true
value of $\eta$ is $\eta = 4/3$.

```{r, echo=FALSE, fig.cap="Bootstrap Distribution of the 0.9-Quantile Ratio. Vertical Lines are the Upper and Lower Bounds from the Percentile Bootstrap Confidence Interval."}
hist(eta.boot, main="Bootstrap Distribution of 0.9-Quantile Ratio", 
     xlab="x", col="grey", las=1)
abline(v=boot.ci.quant[1], lwd=2)
abline(v=boot.ci.quant[2], lwd=2)
```

#### Comparing the Performance of the Bootstrap and Large-Sample Confidence Intervals

* We just saw that the bootstrap and the large-sample confidence intervals gave different answers.

* For this problem, what is the best approach for constructing confidence intervals?

* We can compare the performance of different confidence intervals by
looking at their **coverage probability**.

* For a vector of data $\mathbf{X} = (X_{1}, \ldots, X_{n})$, we can represent
a confidence interval for a parameter of interest $\theta$ as
\begin{equation}
\Big[ L_{\alpha}(\mathbf{X}), U_{\alpha}(\mathbf{X}) \Big]
\end{equation}
    + $L_{\alpha}(\mathbf{X})$ is the lower confidence bound.
    + $U_{\alpha}( \mathbf{X} )$ is the upper confidence bound.


* The coverage probability of a confidence interval $[ L_{\alpha}(\mathbf{X}), U_{\alpha}(\mathbf{X})]$ is
\begin{equation}
P\Big(  L_{\alpha}(\mathbf{X}) \leq \theta \leq U_{\alpha}(\mathbf{X}) \Big), \nonumber
\end{equation}
where we usually construct $L_{\alpha}(\mathbf{X})$ and $U_{\alpha}(\mathbf{X})$ so
that the coverage probability is exactly equal or close to $1 - \alpha$.


* We can estimate this probability via simulation by looking at the following coverage proportion
\begin{equation}
\textrm{CoverProp}_{n_{rep}}(\theta) = \frac{1}{n_{rep}}\sum_{k=1}^{n_{rep}} I\Big( L_{\alpha}(\mathbf{X}^{(k)})  < \theta <  U_{\alpha}(\mathbf{X}^{(k)})  \Big) \nonumber
\end{equation}
    + $n_{rep}$ is the number of simulation replications
    + $X^{(k)}$ is the dataset from the $k^{th}$ simulation replication
    + Each dataset $X^{(k)}$ is generated under the assumption that $\theta$ is the true value of the parameter of interest.

---

* We will compare coverage proportions using the same simulation design we used before for this quantile ratio example. 

* That is, $p = 0.9$ and $X_{i} \sim \textrm{Gamma}(2, 1.5)$ and $Y_{i} \sim \textrm{Gamma}(2, 2)$ with $n = 100$ and $m = 100$.

* Below shows code for a simulation study which uses 1000 simulation replications. It compares the large-sample
confidence interval which uses \@ref(eq:quantile-ratio-approx) with two bootstrap confidence intervals.

```{r, echo=FALSE}
set.seed(1354)
```

```{r}
n <- 100
m <- 100
R <- 500
eta.true <- 4/3

nreps <- 1000
Cover.par.ci <- numeric(nreps)
Cover.bootsd.ci <- numeric(nreps)
Cover.bootquant.ci <- numeric(nreps)
for(k in 1:nreps)  {
    ## Step 1: Generate the Data from Two Groups
    xx <- rgamma(n, shape=2, rate=1.5) 
    yy <- rgamma(m, shape=2, rate=2)

    ## Step 2: Estimate eta from this data
    theta.hat1 <- quantile(xx, probs=0.9)
    theta.hat2 <- quantile(yy, probs=0.9)
    eta.hat <- theta.hat1/theta.hat2    

    ## Step 3: Find confidence interval using large-sample Normal approximation
    xdensity <- density(xx)
    ydensity <- density(yy)
    fx <- approxfun(xdensity$x, xdensity$y)(theta.hat1)
    fy <- approxfun(ydensity$x, ydensity$y)(theta.hat2)
    q1.se.sq <- (.9*.1)/(n*(fx*theta.hat2)^2)
    q2.se.sq <- (.9*.1*theta.hat1*theta.hat1)/(n*fy*fy*((theta.hat2)^4))
    std.err <- sqrt(q1.se.sq + q2.se.sq)
    par.ci <- c(eta.hat - 1.96*std.err, eta.hat + 1.96*std.err)

    ## Step 4: Find bootstrap confidence intervals using R bootstrap replications
    eta.boot <- numeric(R)
    for(r in 1:R)   {
        boot.xx <- sample(xx, size=n, replace = TRUE)
        boot.yy <- sample(yy, size=m, replace = TRUE)
        thetahat.p1 <- quantile(boot.xx, probs=0.9)
        thetahat.p2 <- quantile(boot.yy, probs=0.9)
        eta.boot[r] <- thetahat.p1/thetahat.p2
    }
    boot.ci.sd <- c(eta.hat - 1.96*sd(eta.boot), eta.hat + 1.96*sd(eta.boot))
    boot.ci.quant <- quantile(eta.boot, probs=c(.025, .975))
    
    ## Step 5: Record if the true parameter is covered or not:
    Cover.par.ci[k] <- ifelse(par.ci[1] < eta.true & par.ci[2] >= eta.true, 1, 0)
    Cover.bootsd.ci[k] <- ifelse(boot.ci.sd[1] < eta.true & boot.ci.sd[2] >= eta.true, 
                                 1, 0)
    Cover.bootquant.ci[k] <- ifelse(boot.ci.quant[1] < eta.true & 
                                        boot.ci.quant[2] >= eta.true, 1, 0)
}
```

* The coverage proportions for each of the methods are:
```{r}
mean(Cover.par.ci)
mean(Cover.bootsd.ci)
mean(Cover.bootquant.ci)
```

* Using these simulated outcomes, we can also construct $95\%$ confidence intervals for the coverage probabilities:

```{r kable, echo=FALSE, results="asis"}
library(xtable)
A <- matrix(0, 3, 3)
A[1,] <- c(mean(Cover.par.ci) - 1.96*sd(Cover.par.ci)/sqrt(1000), mean(Cover.par.ci), mean(Cover.par.ci) + 1.96*sd(Cover.par.ci)/sqrt(1000))
A[2,] <- c(mean(Cover.bootsd.ci) - 1.96*sd(Cover.bootsd.ci)/sqrt(1000), mean(Cover.bootsd.ci), mean(Cover.bootsd.ci) + 1.96*sd(Cover.bootsd.ci)/sqrt(1000))
A[3,] <- c(mean(Cover.bootquant.ci) - 1.96*sd(Cover.bootquant.ci)/sqrt(1000), mean(Cover.bootquant.ci), mean(Cover.bootquant.ci) + 1.96*sd(Cover.bootquant.ci)/sqrt(1000))
rownames(A) <- c("Large-Sample Approximation", "Bootstrap Std. Err.", "Bootstrap Percentile")
colnames(A) <- c("Lower CI","Estimate", "Upper CI")
tab <- xtable(A, digits=c(3, 3, 3, 3), align=c("c","c","c","c"), caption="Estimates and Confidence Intervals for the Coverage Probabilities of Different Methods.")
print(tab, type="html", comment=FALSE)
```


## Why is the Bootstrap Procedure Reasonable?

* As mentioned before, our original motivation for the bootstrap was to find an estimate of 
$\textrm{Var}(T_{n})$ where 

* The statistic $T_{n}$ can be thought of as a function of our sample 
\begin{equation}
T_{n} = h(X_{1}, \ldots, X_{n}) \nonumber 
\end{equation}
where $X_{1}, \ldots, X_{n}$ is an i.i.d. sample with cumulative distribution function $F$.

* If we had a way of simulating data $X_{i}^{(k)}$ from $F$, we could estimate $\textrm{Var}(T_{n})$
with the following quantity
\begin{eqnarray}
\widehat{\textrm{Var}( T_{n} )} &=& \sum_{k=1}^{K}\Big( h(X_{1}^{(k)}, \ldots, X_{n}^{(k)}) - \frac{1}{K}\sum_{k=1}^{K} h(X_{1}^{(k)}, \ldots, X_{n}^{(k)})  \Big)^{2} \nonumber \\
&=& \sum_{k=1}^{K}\Big( T_{n}^{(k)} - \frac{1}{K}\sum_{k=1}^{K} T_{n}^{(k)}  \Big)^{2}  \nonumber 
\end{eqnarray}
    + $X_{1}^{(k)}, \ldots, X_{n}^{(k)}$ is an i.i.d. sample from $F$. 
    + $T_{n}^{(k)} = h(X_{1}^{(k)}, \ldots, X_{n}^{(k)})$ is the value of out statistic of interest from the $k^{th}$ simulated dataset.

---

* In practice, $F$ is unknown, and we cannot simulate data from $F$.

* The main idea behind the bootstrap is that the empirical distribution function
$\hat{F}_{n}$ is a very good estimate of $F$. 

* How to simulate data from $\hat{F}_{n}$ rather than $F$?







