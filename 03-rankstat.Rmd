# (PART) Nonparametric Testing {-} 

# Rank and Sign Statistics {#rank-tests}

<!--   ## Introduction

Start with t-test example, difference in means is sufficient for superiority

Give example of type of tests we are interested in.

Why ranks and why nonparametric testing?

(reduce influence of outliers)
-->

## Ranks

### Definition

* Suppose we have $n$ observations $\mathbf{X} = (X_{1}, \ldots, X_{n})$. The **rank** of the $i^{th}$ observation $R_{i}$ is defined as
\begin{equation}
R_{i} = R_{i}(\mathbf{X}) = \sum_{j=1}^{n} I( X_{i} \geq X_{j}) 
(\#eq:rankdef)
\end{equation}
where
\begin{equation}
I(X_{i} \geq X_{j}) 
= \begin{cases}
1 & \text{ if } X_{i} \geq X_{j} \\
0 & \text{ if } X_{i} < X_{j}
\end{cases}
\end{equation}
* The largest observation has a rank of $n$.
* The smallest observation has a rank of $1$ (if there are no ties).
* I'm using the notation $R_{i}(\mathbf{X})$ to emphasize that the rank
of the $i^{th}$ observations depends on the entire vector of observations
rather than only the value of $X_{i}$.


* You can compute ranks in **R** using the **rank** function:
```{r }
x <- c(3, 7, 1, 12, 6)  ## 5 observations
rank(x)
```

### Handling Ties

* In the definition of ranks shown in \@ref(eq:rankdef), tied observations
receive their maximum possible rank. 
* For example, suppose that $(X_{1}, X_{2}, X_{3}, X_{4}) = (0, 1, 1, 2)$. 
In this case, one could argue whether both observations 2 and 3 should be ranked
$2^{nd}$ or $3^{rd}$ while observations $1$ and $4$ should unambiguously receive
ranks of $1$ and $4$ respectively.
* Under definition \@ref(eq:rankdef), both observations $2$ and $3$ receive a rank of $3$.

* In **R**, handling ties that is consistent with definition \@ref(eq:rankdef) is done using the **ties.method = "max"** argument
```{r }
x <- c(0, 1, 1, 2)  
rank(x, ties.method="max")
```
* The default in **R** is to replace the ranks of tied observations with their "average" rank
```{r }
x <- c(0, 1, 1, 2)  
rank(x)

y <- c(2, 9, 7, 7, 3, 2, 1)
rank(y, ties.method="max")
rank(y)
```

---

* When defining ranks using the "average" or "midrank" approach to handling ties, replaces
tied ranks with the average of the two "adjacent" ranks. 

* For example, if we have a vector of ranks $(R_{1}, R_{2}, R_{3}, R_{4})$ where $R_{2} = R_{3} =3$ and $R_{1} = 4$ and $R_{4} = 1$, then the vector of modified ranks using the "average" approach to handling ties
would be
\begin{equation}
(R_{1}', R_{2}', R_{3}', R_{4}') = \Big( 4, \frac{4 + 1}{2}, \frac{4 + 1}{2}, 1 \Big)
\end{equation}

* The "average" approach is the most common way of handling ties when computing the
Wilcoxon rank sum statistic.


### Properties of Ranks
Suppose $(X_{1}, \ldots, X_{n})$ is random sample from a continuous distribution $F$ (so that the probability
of ties is zero). Then, the following properties hold for the associated ranks $R_{1}, \ldots, R_{n}$.

* Each $R_{i}$ follows a discrete uniform distribution
\begin{equation}
P(R_{i} = j) = 1/n, \quad \text{for any } j = 1, \ldots,n.
\end{equation}
* The expectation of $R_{i}$ is
\begin{equation}
E( R_{i} ) = \sum_{j=1}^{n} j P(R_{i} = j) = \frac{1}{n}\sum_{j=1}^{n} j = \frac{(n+1)}{2}
\end{equation}
* The variance of $R_{i}$ is
\begin{equation}
\text{Var}( R_{i} ) = E( R_{i}^{2} ) - E(R_{i})^{2}
= \frac{1}{n}\sum_{j=1}^{n} j^{2}  - \Big( \frac{n+1}{2} \Big)^{2}
= \frac{ n^{2} - 1}{12}
\end{equation}
* The random variables $R_{1}, \ldots, R_{n}$ are **not** independent (why?). However,
the vector $\mathbf{R}_{n} = (R_{1}, \ldots, R_{n})$ is uniformly distributed
on the set of $n!$ permutations of $(1,2,\ldots,n)$.

---

**Exercise 3.1**: Suppose $X_{1}, X_{2}, X_{3}$ are i.i.d. observations from a continuous
distribution function $F_{X}$. Compute the covariance matrix of the vector 
of ranks $\big( R_{1}(\mathbf{X}), R_{2}(\mathbf{X}), R_{3}( \mathbf{X} ) \big)$.

**Exercise 3.2**: Again, suppose that $X_{1}, X_{2}, X_{3}, X_{4}$ are i.i.d. observations from a continuous
distribution function $F_{X}$. Let $T= R_{1}( \mathbf{X} ) + R_{2}(\mathbf{X})$. Compute $P( T = j )$ 
for $j = 3, 4, 5, 6, 7$.

---


## The Wilcoxon Rank Sum (WRS) Test: A Two-Sample Test

### Goal of the Test

* The Wilcoxon Rank Sum (WRS) test (sometimes referred to as the Wilcoxon-Mann-Whitney test) is a popular,
rank-based two-sample test.

* The WRS test is used to test whether or not observations from one group tend to be larger (or smaller) than observations
from the other group. 

* Suppose we have observations from two groups: $X_{1}, \ldots, X_{n} \sim F_{X}$ and $Y_{1}, \ldots, Y_{m} \sim F_{Y}$.

* Roughly speaking, the WRS tests the following hypothesis
\begin{eqnarray}
H_{0}: && F_{X} = F_{Y} \quad \textrm{ versus }  \\
H_{A}: && \textrm{Observations from } F_{X} \textrm{ tend to be larger than observations from } F_{Y} \nonumber
(\#eq:general-wilcoxon-hypothesis)
\end{eqnarray}

---

* What is meant by "tend to be larger" in the alternative hypothesis?

* Two common ways of stating the alternative hypothesis for the WRS include
    1. The stochastic dominance alternative
\begin{eqnarray}
H_{0}: & & F_{X} = F_{Y} \quad \textrm{ versus } \nonumber \\
H_{A}: & & F_{X} \textrm{ is stochastically larger than } F_{Y} 
(\#eq:stochasticlarger-formulation)
\end{eqnarray}
    2. The "shift" alternative
\begin{eqnarray}
H_{0}: & & F_{X} = F_{Y} \quad \textrm{ versus } \nonumber \\
H_{A}: & & F_{X}(t) = F_{Y}(t - \Delta), \Delta > 0.
(\#eq:shift-formulation)
\end{eqnarray}
* A distribution function $F_{X}$ is said to be stochastically larger than
$F_{Y}$ if $F_{X}(t) \leq F_{Y}(t)$ for all $t$ with $F_{X}(t) < F_{Y}(t)$
for at least one value of $t$.

* Note that the "shift alternative" implies stochastic dominance.

* Why do we need to specify an alternative?

---

* It is often stated that the WRS test is a test
of equal medians.

* This is true under the assumption that the 
relevant alternative is of the form $F_{X}(t) = F_{Y}(t - \Delta)$.

* However, one could have a scenario where the two groups have equal medians, but 
the WRS test has a very high probability of rejecting $H_{0}$.

* In addition, in many applications, it is difficult to justify
that the "shift alternative" is a reasonable model.

* An alternative is to view the WRS test as performing the following
hypothesis test:
\begin{eqnarray}
H_{0}: && P(X_{i} > Y_{j}) + \tfrac{1}{2}P(X_{i} = Y_{j}) = 1/2 \quad \textrm{ versus } \\
H_{A}: && P(X_{i} > Y_{j}) + \tfrac{1}{2}P(X_{i} = Y_{j}) > 1/2
(\#eq:mw-formulation)
\end{eqnarray}
See  @divine2018 for more discussion around this formulation of the
WRS test.

* The hypothesis test \@ref(eq:mw-formulation) makes fewer assumptions
about how $F_{X}$ and $F_{Y}$ are related and is, in many cases, more interpretable.

* For example, in medical applications, it is often more natural to 
answer the question: what is the probability that the outcome
under treatment 1 is better than the outcome under treatment 2.

* The justification of hypothesis test \@ref(eq:mw-formulation) comes through
the close connection between the WRS test statistic $W$ and the Mann-Whitney statistic $U_{MW}$.
Specifically, $W = U_{MW} + n(n+1)/2$. (Although, often $U_{MW}$ is defined as 
$U_{MW} = mn + n(n+1)/2 - W$).

* The Mann-Whitney statistic divided by $mn$ is an estimate of the probability:
\begin{equation}
P(X_{i} > Y_{j}) + \tfrac{1}{2}P(X_{i} = Y_{j}) = 1/2.
\end{equation}


### Definition of the WRS Test Statistic

* The WRS test statistic is based on computing the sum of ranks (ranks based on the pooled sample)
in one group.

* If observations from group 1 tend to be larger than those from group 2, the average rank from group 1 should exceed the
average rank from group 2. 

* A sufficiently large value of the average rank from group 1 will allow us to reject $H_{0}$ 
in favor of $H_{A}$.

---

* We will define the pooled data vector $\mathbf{Z}$ as 
\begin{equation}
\mathbf{Z} = (X_{1}, \ldots, X_{n}, Y_{1}, \ldots, Y_{m})
\end{equation}
This is a vector with length $n + m$.

* The Wilcoxon rank-sum test statistic $W$ for testing hypotheses of the form \@ref(eq:general-wilcoxon-hypothesis)
is then defined as
\begin{equation}
W = \sum_{i=1}^{n} R_{i}( \mathbf{Z} )
(\#eq:wrs-formula)
\end{equation}

* In other words, the WRS test statistic is the sum of the ranks for those observations coming 
from group 1 (i.e., the group with the $X_{i}$ as observations).

* If the group 1 observations tend to, in fact, be larger than the group 2 observations,
then we should expect the sum of the ranks in this group to be larger than the sum of the
ranks from group 2.

--- 

* Under $H_{0}$, we can treat both $X_{i}$ and $Y_{i}$ as being observations coming from
a common distribution function $F$.

* Hence, the expectation of $R_{i}(\mathbf{Z})$ under the null hypothesis is
\begin{equation}
E_{H_{0}}\{ R_{i}(\mathbf{Z}) \} = \frac{n + m + 1}{2}
\end{equation}
and thus the expectation of $W$ under $H_{0}$
\begin{equation}
E_{H_{0}}( W ) = \sum_{i=1}^{n} E_{H_{0}}\{ R_{i}( \mathbf{Z} ) \}
= \frac{ n(n + m + 1)  }{ 2 }
\end{equation}

* It can be shown that the variance of $W$ under the null hypothesis is
\begin{equation}
\textrm{Var}_{H_{0}}( W ) = \frac{mn(m + n + 1)}{12}
\end{equation}

### Computing p-values for the WRS Test

**Exact Distribution**

* The p-value is found by computing the probability
\begin{equation}
\textrm{p-value} = P_{H_{0}}( W \geq w_{obs})
\end{equation}
where $w_{obs}$ is the observed WRS test statistic that 
we get from our data.

* Computing p-values for the WRS test requires us to 
work with the **null distribution** of $W$. That is,
the distribution of $W$ under the assumption that
$F_{X} = F_{Y}$.

* The exact null distribution is found by using the fact
that each possible ordering of the ranks has the same probability.
That is,
\begin{equation}
P\{ R_{1}(\mathbf{Z}) = r_{1}, \ldots, R_{n+m}(\mathbf{Z}) =  r_{n+m} \} = \frac{1}{(n + m)!},
\end{equation}
where $(r_{1}, \ldots, r_{n+m})$ is any permutation of the set $\{1, 2, \ldots, n + m\}$.
Note that the null distribution only depends on $n$ and $m$.

* Also, there are ${n + m \choose n}$ possible ways to assign distinct ranks to group 1.

* Consider an example with $n = m = 2$. In this case, there are ${4 \choose 2} = 6$ distinct
ways to assign 2 ranks to group 1.
What is the null distribution of the WRS test statistic? Try to verify that
\begin{eqnarray}
P_{H_{0}}( W = 7) &=& 1/6 \nonumber \\
P_{H_{0}}( W = 6 ) &=& 1/6 \nonumber \\
P_{H_{0}}(W = 5) &=& 1/3  \nonumber \\
P_{H_{0}}( W = 4 ) &=& 1/6  \nonumber \\
P_{H_{0}}(W = 3) &=& 1/6. \nonumber 
\end{eqnarray}

---

**Large-Sample Approximate Distribution**

* Looking at \@ref(eq:wrs-formula), we can see that the
WRS test statistic is a sum of nearly independent random variables 
(at least nearly independent for large $n$ and $m$).

* Thus, we can expect that an appropriately centered and scaled
version of $W$ should be approximately Normally distributed (recall the Central Limit Theorem).

* The standardized version $\tilde{W}$ of the WRS is defined as
\begin{equation}
\tilde{W} = \frac{W - E_{H_{0}}(W)}{ \sqrt{\textrm{Var}_{H_{0}}(W) }  }
= \frac{W - n(n+m+1)/2}{ \sqrt{ mn(n + m + 1)/12 }  }
\end{equation}

* Under $H_{0}$, $\tilde{W}$ converges in distribution to a Normal$(0,1)$ random variable.

* A p-value using this large-sample approximation would then be computed in the following
way
\begin{eqnarray}
\textrm{p-value} &=& P_{H_{0}}( W \geq w_{obs}) 
= P\Bigg( \frac{W - n(n+m+1)/2}{ \sqrt{ mn(n + m + 1)/12 }  } \geq \frac{w_{obs} - n(n+m+1)/2}{ \sqrt{ mn(n + m + 1)/12 }  }\Bigg)
\nonumber \\
&=& P_{H_{0}}\Big( \tilde{W} \geq \frac{w_{obs} - n(n+m+1)/2}{ \sqrt{ mn(n + m + 1)/12 }  }\Big)
= 1 - \Phi\Bigg( \frac{w_{obs} - n(n+m+1)/2}{ \sqrt{ mn(n + m + 1)/12 }  }  \Bigg), \nonumber
\end{eqnarray}
where $\Phi(t)$ denotes the cumulative distribution function of a standard Normal random variable.

* Often, in practice, a continuity correction is applied when using this large-sample approximation.
For example, we would compute the probability $P_{H_{0}}(W \geq w_{obs} - 0.5)$ with the Normal approximation
rather than $P_{H_{0}}(W \geq w_{obs})$ directly.

---

* Many statistical software packages (including **R**) will not compute p-values using the exact distribution in 
the presence of ties. 

* The **coin** package in **R** does allow you to perform a permutation test in the presence of ties.

* A "two-sided" Wilcoxon rank sum test can also be performed. The two-sided 
hypothesis tests could either be stated as 
\begin{eqnarray}
H_{0}: & & F_{X} = F_{Y} \quad \textrm{ versus } \nonumber \\
H_{A}: & & F_{X} \textrm{ is stochastically larger or smaller than } F_{Y} 
\end{eqnarray}
or
\begin{eqnarray}
H_{0}: & & F_{X} = F_{Y} \quad \textrm{ versus } \nonumber \\
H_{A}: & & F_{X}(t) = F_{Y}(t - \Delta), \Delta \neq 0.
\end{eqnarray}
or
\begin{eqnarray}
H_{0}: && P(X_{i} > Y_{i}) + \tfrac{1}{2}P(X_{i} = Y_{i}) = 1/2 \quad \textrm{ versus } \\
H_{A}: && P(X_{i} > Y_{i}) + \tfrac{1}{2}P(X_{i} = Y_{i}) \neq 1/2
\end{eqnarray}

---

**Exercise 3.3.** Using the exact distribution, what is the smallest
possible one-sided p-value associated with the WRS test 
for a fixed value of $n$ and $m$ (assuming the probability of ties is zero)? 

---

<!-- * Give exercise, compute p-values for Wilcoxon test where
we have two populations. both are Normally distributed
with mean zero but different variances. -->


### Computing the WRS test in R
* To illustrate performing the WRS test in **R**, we can use the **wine** dataset from the **rattle.data** package.
This dataset is also available from the UCI Machine Learning Repository.
```{r }
library(rattle.data)
head(wine)
```

* This dataset contains three types of wine. We will only consider the first two. 
```{r}
wine2 <- subset(wine, Type==1 | Type==2)
wine2$Type <- factor(wine2$Type)
```

* Let's consider the difference in the level of magnesium across the two types of wine.
```{r, echo=FALSE}
par(mfrow=c(1,2))
hist(wine2$Magnesium[wine2$Type==1], xlab="Magnesium", main="Wine Type 1", las=1)
hist(wine2$Magnesium[wine2$Type==2], xlab="Magnesium", main="Wine Type 2", las=1)
par(mfrow=c(1,1))
boxplot(Magnesium ~ Type, data=wine2, col="grey", las=1, xlab="Wine Type")
```

* Suppose we are interested in testing whether or not magnesium levels in 
Type 1 wine are generally larger than magnesium levels in Type 2 wine.
This can be done with the following code
```{r}
wilcox.test(x=wine2$Magnesium[wine2$Type==1], y=wine2$Magnesium[wine2$Type==2], 
            alternative="greater")
```

You could also use the following code (just be careful about the ordering of the levels of **Type**)
```{r}
wilcox.test(Magnesium ~ Type, data=wine2, alternative="greater")
```

* What is the value of the WRS test statistic? We can code this directly 
with the following steps:
```{r}
W <- wilcox.test(x=wine2$Magnesium[wine2$Type==1], y=wine2$Magnesium[wine2$Type==2])

n <- sum(wine2$Type==1)
m <- sum(wine2$Type==2)
zz <- rank(wine2$Magnesium) ## vector of pooled ranks
sum(zz[wine2$Type==1])  ## The WRS test statistic
```

* The statistic returned by the **wilcox.test** function is actually equal to $W - n(n+1)/2$ not $W$
```{r}
sum(zz[wine2$Type==1]) - n*(n + 1)/2
W$statistic
```

* $\{ W - n(n+1)/2 \}$ is equal to the Mann-Whitney statistic. Thus, **W$statistic/(mn)** is
an estimate of the probability $P(X_{i} > Y_{j}) + P(X_{i} = Y_{j})/2$.
```{r}
W$statistic/(m*n)
```

* Let's check how the Mann-Whitney statistic matches a simulation-based estimate of this probability
```{r}
ind1 <- which(wine2$Type==1)
ind2 <- which(wine2$Type==2)
xgreater <- rep(0, 100)
for(k in 1:100) {
    xi <- sample(ind1, size=1)
    yi <- sample(ind2, size=1)
    xgreater[k] <- ifelse(wine2$Magnesium[xi] > wine2$Magnesium[yi], 1, 0)
}
mean(xgreater)  ## estimate of this probability
```


### Additional Notes for the WRS test

#### Comparing Ordinal Data

* The WRS test is often suggested when comparing categorical data which are **ordinal**.

* For example, we might have 4 categories: 
    + Poor
    + Fair
    + Good
    + Excellent
    
* In this case, there is a natural ordering of the categories
but any numerical values assigned to these categories would be arbitrary.

* In such cases, we might be interested in testing whether or not outcomes tend to be
better in one group than the other rather than simply comparing whether or not
the distribution is different between the two groups.

* A WRS test is useful here since we can still compute ranks without having to 
choose aribtrary numbers for each category. 

* Thinking of the "probability greater than alternative \@ref(eq:mw-formulation)" 
or "stochastically larger than alternative \@ref(eq:stochasticlarger-formulation)" interpretation 
of the WRS test is probably more reasonable than the "shift alternative \@ref(eq:shift-formulation)" interpretation. 

* Note that there will probably be many ties when comparing ordinal data.

---

* The Hodges-Lehmann Estimator $\hat{\Delta}$ is an estimator of $\Delta$ in the location-shift model
\begin{equation}
F_{X}(t) = F_{Y}(t - \Delta) \nonumber
\end{equation}

* The Hodges-Lehmann is defined as the median difference among all possible (group 1, group 2) pairs. 
Specifically,
\begin{equation}
\hat{\Delta} = \textrm{median}\{ (X_{i} - Y_{j}); i=1,\ldots,n; j=1,\ldots,m \} \nonumber
\end{equation}

* We won't discuss the Hodges-Lehmann estimator in detail in this course, but in
many statistical software packages, the
Hodges-Lehmann is often reported when computing the WRS test.

* In **R**, the Hodges-Lehmann estimator can be obtained by using the **conf.int=TRUE**
argument in the **wilcox.test** function
```{r}
WC <- wilcox.test(x=wine2$Magnesium[wine2$Type==1], y=wine2$Magnesium[wine2$Type==2],
                  conf.int=TRUE)
WC$estimate     ## The Hodges-Lehmann estimate
```


## One Sample Tests

### The Sign Test

#### Motivation and Definition
* Suppose we have observations $D_{1}, \ldots, D_{n}$ which arise from the following model
\begin{equation}
D_{i} = \theta + \varepsilon_{i}, \nonumber 
\end{equation}
where $\varepsilon_{i}$ are iid random variables each with distribution function $F_{\epsilon}$
that is assumed to have a median of zero.

* The distribution function of $D_{i}$ is then
\begin{equation}
F_{D}(t) = P(D_{i} \leq t) = P(\varepsilon_{i} \leq t - \theta) = F_{\epsilon}(t - \theta)
\end{equation}

* Likewise the density function $f_{D}(t)$ of $D_{i}$ is given by
\begin{equation}
f_{D}(t) = f_{\epsilon}(t - \theta)
\end{equation}

* In this context, $\theta$ is usually referred to as a **location parameter**.

* The goal here is to test $H_{0}: \theta = \theta_{0}$ vs. $H_{A}: \theta > \theta_{0}$. (Often, $\theta_{0} = 0$).

---

* This sort of test usually comes up in the context of **paired data**.
Common examples include
    + patients compared "pre and post treatment"
    + students before and after the introduction of a new teaching method 
    + comparison of "matched" individuals who are similar (e.g., same age, sex, education, etc.)
    + comparing consistency of measurements made on the same objects

```{r kable, echo=FALSE, results="asis"}
library(xtable)
A <- data.frame(Baseline_Measure=c("X1", "X2", "X3","X4"), Post_Treatment_Measure=c("Y1", "Y2", "Y3","Y4"))
rownames(A) <- c("Patient 1", "Patient 2", "Patient 3", "Patient 4")
tab <- xtable(A, align=rep("c", 3))
print(tab, type="html", comment=FALSE)
```
   
* In such cases, we have observations $X_{i}$ and $Y_{i}$ for $i = 1,\ldots n$ where
it is not necessarily reasonable to think of $X_{i}$ and $Y_{i}$ as independent.

* We can define $D_{i} = X_{i} - Y_{i}$ as the difference in the $i^{th}$ pair.

* With this setup, a natural question is whether or not the differences $D_{i}$ tend to be 
greater than zero or not.

---

* The **sign** statistic $S_{n}$ is defined as
\begin{equation}
S = \sum_{i=1}^{n} I( D_{i} > 0)
(\#eq:sign-statistic)
\end{equation}

* If the null hypothesis $H_{0}: \theta = 0$ is true, then we should expect that roughly half
of the observations will be positive.

* This suggests that we will reject $H_{0}$ if $S \geq c$ where $c$ is a 
number that is greater than $n/2$.

#### Null Distribution and p-values

* Notice that the sign statistic defined in \@ref(eq:sign-statistic) is the sum of independent
Bernoulli random variable. 

* That is, we can think of $Z_{i} = I(D_{i} > 0)$ as a random variable with success probability
$p( \theta )$ where the formula for $p( \theta )$ is
\begin{equation}
p(\theta) = P(Z_{i} > 0) = 1 - F_{D}(0) = 1 - F_{\epsilon}( -\theta )
\end{equation}

* This implies that $S_{n}$ is a binomial random variable
with $n$ trials and success probability $p(\theta)$. 
That is, 
\begin{equation}
S \sim \textrm{Binomial}(n, p(\theta) )
\end{equation}

* Because $p(0) = 1/2$, $S_{n} \sim \textrm{Binomial}(n, 1/2 )$ under $H_{0}$.

* Notice that the "null distribution" of the sign statistic is "distribution free"
in the sense that the distribution does not depend on the distribution of $D_{i}$.

* The p-value for the sign test can be computed by
\begin{equation}
\textrm{p-value} = P_{H_{0}}(S \geq s_{obs}) = \sum_{j=s_{obs}}^{n} {n \choose j} \frac{1}{2^{n}},
\end{equation}
where $s_{obs}$ is the observed value of the sign statistic.

```{r}
### How to compute the p-value for the sign test using R
xx <- rnorm(100)
sign.stat <- sum(xx > 0)
1 - pbinom(sign.stat - 1, size=100, prob=1/2) ## p-value for sign test
```

* The reason that this is the right expression using **R** is that for any positive integer $w$
\begin{equation}
P_{H_{0}}(S \geq w) = 1 - P_{H_{0}}(S < w) = 1 - P_{H_{0}}(S \leq w - 1)
\end{equation}
and the **R** function **pbinom(t, n, prob)** computes $P(X \leq t)$ where $X$ is 
a binomial random variable with $n$ trials and success probability **prob**.

* You can also perform the one-sided sign test by using the **binom.test** function in **R**.
```{r}
btest <- binom.test(sign.stat, n=100, alternative="greater") 
btest$p.value
```

#### Two-sided Sign Test

* Notice that the number of negative values of $D_{i}$ can be expressed as
\begin{equation}
\sum_{i=1}^{n} I(D_{i} < 0) = n - S
\end{equation}
if there are no observations that equal zero exactly. Large value of $n - S$
would be used in favor of another possible one-sided alternative $H_{A}: \theta < 0$.

* If we now want to test the two-sided alternative
\begin{equation}
H_{0}: \theta = 0 \quad \textrm{ vs. }  \quad H_{A}: \theta \neq 0 \nonumber
\end{equation}
you would need to compute the probability under the null hypothesis of observing
a "more extreme" observation than the one that was actually observed.

* Extreme is defined by thinking about the fact that we would have rejected $H_{0}$
if either $S$ or $n - S$ were very large.

* For example, if $n = 12$, then the expected value of the sign statistic would be $6$.
If $s_{obs} = 10$, then the collection of "more extreme" events then this would be
$\leq 2$ and $\geq 10$.

* The two-sided p-value is determined by looking at the tail probabilities on both sides
\begin{equation}
\textrm{p-value} = 
\begin{cases}
P_{H_{0}}(S \geq s_{obs}) + P_{H_{0}}(S \leq n - s_{obs}) & \textrm{ if } s_{obs} \geq n/2 \\
P_{H_{0}}(S \leq s_{obs}) + P_{H_{0}}(S \geq n - s_{obs}) & \textrm{ if } s_{obs} < n/2
\end{cases}
\end{equation}

* It actually works out that
\begin{equation}
\textrm{p-value} = 
\begin{cases}
2 P_{H_{0}}(S \geq s_{obs})   & \textrm{ if } s_{obs} \geq n/2 \\
2 P_{H_{0}}(S \leq s_{obs})   & \textrm{ if } s_{obs} < n/2
\end{cases}
\end{equation}

* Also, you can note that this p-value would be the same that you would get from performing the test 
$H_{0}: p = 1/2$ vs. $H_{A}: p \neq 1/2$ when it is assumed that $S_{n} \sim \textrm{Binomial}(n, p)$.

* Another note: It is often suggested that one should drop observations which are exactly zero
when performing the sign test.


### The Wilcoxon Signed Rank Test

* The Wilcoxon signed rank test can be applied
under the same scenario that we used the sign test.

* One criticism of the sign test is that it ignores the magnitude 
of the observations.

* For example, the sign test statistic $S$ treats observations 
$D_{i} = 0.2$ and $D_{i}=3$ the same.

* The **Wilcoxon signed rank statistic** $T^{+}$ weights the positive
indicators $I( D_{i} > 0)$ by the rank of its absolute value.

* Specifically, the Wilcoxon signed rank statistic is defined as
\begin{equation}
T^{+} = \sum_{i=1}^{n} I( D_{i} > 0)R_{i}( |\mathbf{D}| )
\end{equation}

* Here, $R_{i}( \mathbf{D})$ is the rank of the $i^{th}$ element from the vector
$|\mathbf{D}| = (|D_{1}|, |D_{2}|, \ldots, |D_{n})$.

---

**Exercise 3.4.** Suppose we had data $(-2, 1, -1/2, 3/2, 3)$. What would 
be the value of the Wilcoxon signed rank statistic?

---

* Expectation under the null hypothesis..

#### Exact Distribution

#### Asymptotic Distribution


### Using R to Perform the Sign and Wilcoxon Tests 

* Let's first look at the **Meat** data from the **PairedData** **R** package.

* This data set contains 20 observations with measures of fat percentage using different 
measuring techniques.
 
```{r}
library(PairedData, quietly=TRUE, warn.conflicts=FALSE) ## loading PairedData package
data(Meat)  ## loading Meat data
head(Meat)
```

* Define the differences $D_{i}$ as the Babcock measurements minus the AOAC measures
```{r}
DD <- Meat[,2] - Meat[,1]
hist(DD, main="Meat Data", xlab="Difference in Measured Fat Percentage", las=1)
summary(DD)
```

* Let's first test the hypothesis $H_{0}: \theta = 0$ vs. $H_{A}: \theta \neq 1/2$ using
the two.sided sign test
```{r}
binom.test(sum(DD > 0), n = length(DD), p=0.5)$p.value
```

## Power and Comparisons with Parametric Tests

### Power of Tests

* The **power** of a test is the probability
that a test rejects the null hypothesis when the 
alternative hypothesis is true.



## Thinking about Rank statistics more generally

## Notes 

* Additional reading which covers the material discussed in this chapter includes:
    + Chapters 3-4 from @hollander2013


